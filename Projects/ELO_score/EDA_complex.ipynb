{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "394aeff3-42e0-4f06-9748-93c933cb34a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>games</th>\n",
       "      <th>tours</th>\n",
       "      <th>time_control</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tour_1</th>\n",
       "      <td>tournament_1</td>\n",
       "      <td>2014-01-08</td>\n",
       "      <td>2014-01-17</td>\n",
       "      <td>[{'white': '贾叶珍', 'black': '范辰妮', 'date': '201...</td>\n",
       "      <td>9</td>\n",
       "      <td>rapid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tour_2</th>\n",
       "      <td>tournament_1</td>\n",
       "      <td>2014-01-08</td>\n",
       "      <td>2014-01-17</td>\n",
       "      <td>[{'white': '曹灵缨', 'black': '陆桂姐', 'date': '201...</td>\n",
       "      <td>9</td>\n",
       "      <td>rapid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tour_3</th>\n",
       "      <td>tournament_1</td>\n",
       "      <td>2014-01-08</td>\n",
       "      <td>2014-01-17</td>\n",
       "      <td>[{'white': '刘家坚', 'black': '沈岚鸿', 'date': '201...</td>\n",
       "      <td>9</td>\n",
       "      <td>rapid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tour_4</th>\n",
       "      <td>tournament_1</td>\n",
       "      <td>2014-01-08</td>\n",
       "      <td>2014-01-17</td>\n",
       "      <td>[{'white': '沈岚鸿', 'black': '李文子', 'date': '201...</td>\n",
       "      <td>9</td>\n",
       "      <td>rapid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tour_5</th>\n",
       "      <td>tournament_1</td>\n",
       "      <td>2014-01-08</td>\n",
       "      <td>2014-01-17</td>\n",
       "      <td>[{'white': '范存妞', 'black': '沈岚鸿', 'date': '201...</td>\n",
       "      <td>9</td>\n",
       "      <td>rapid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                name  start_date    end_date  \\\n",
       "tour_1  tournament_1  2014-01-08  2014-01-17   \n",
       "tour_2  tournament_1  2014-01-08  2014-01-17   \n",
       "tour_3  tournament_1  2014-01-08  2014-01-17   \n",
       "tour_4  tournament_1  2014-01-08  2014-01-17   \n",
       "tour_5  tournament_1  2014-01-08  2014-01-17   \n",
       "\n",
       "                                                    games  tours time_control  \n",
       "tour_1  [{'white': '贾叶珍', 'black': '范辰妮', 'date': '201...      9        rapid  \n",
       "tour_2  [{'white': '曹灵缨', 'black': '陆桂姐', 'date': '201...      9        rapid  \n",
       "tour_3  [{'white': '刘家坚', 'black': '沈岚鸿', 'date': '201...      9        rapid  \n",
       "tour_4  [{'white': '沈岚鸿', 'black': '李文子', 'date': '201...      9        rapid  \n",
       "tour_5  [{'white': '范存妞', 'black': '沈岚鸿', 'date': '201...      9        rapid  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "File1=pd.read_json(r\"C:\\Users\\chaitanya\\tournament_1.json\")\n",
    "File1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ce8db88b-5c49-45c8-a4b3-95bbc55b8d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                name  start_date    end_date  \\\n",
      "tour_1  tournament_1  2014-01-08  2014-01-17   \n",
      "tour_2  tournament_1  2014-01-08  2014-01-17   \n",
      "tour_3  tournament_1  2014-01-08  2014-01-17   \n",
      "tour_4  tournament_1  2014-01-08  2014-01-17   \n",
      "tour_5  tournament_1  2014-01-08  2014-01-17   \n",
      "\n",
      "                                                    games  tours time_control  \n",
      "tour_1  [{'white': '贾叶珍', 'black': '范辰妮', 'date': '201...      9        rapid  \n",
      "tour_2  [{'white': '曹灵缨', 'black': '陆桂姐', 'date': '201...      9        rapid  \n",
      "tour_3  [{'white': '刘家坚', 'black': '沈岚鸿', 'date': '201...      9        rapid  \n",
      "tour_4  [{'white': '沈岚鸿', 'black': '李文子', 'date': '201...      9        rapid  \n",
      "tour_5  [{'white': '范存妞', 'black': '沈岚鸿', 'date': '201...      9        rapid  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Specify the URL to the raw JSON file\n",
    "url = 'https://github.com/SunilGorantla/QT_Batch_0011/raw/main/Machine_Learning/datasets/chess/train/tournament_1.json'\n",
    "\n",
    "# Step 2: Read the JSON file from the URL into a pandas DataFrame\n",
    "data = pd.read_json(url)\n",
    "\n",
    "# Step 3: Display the first few rows of the DataFrame\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8a841424-a628-48a6-a32f-6ed23561a8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              name  start_date    end_date  \\\n",
      "0     tournament_1  2014-01-08  2014-01-17   \n",
      "1     tournament_1  2014-01-08  2014-01-17   \n",
      "2     tournament_1  2014-01-08  2014-01-17   \n",
      "3     tournament_1  2014-01-08  2014-01-17   \n",
      "4     tournament_1  2014-01-08  2014-01-17   \n",
      "5     tournament_1  2014-01-08  2014-01-17   \n",
      "6     tournament_1  2014-01-08  2014-01-17   \n",
      "7     tournament_1  2014-01-08  2014-01-17   \n",
      "8     tournament_1  2014-01-08  2014-01-17   \n",
      "9    tournament_10  2014-01-15  2014-02-08   \n",
      "10   tournament_10  2014-01-15  2014-02-08   \n",
      "11   tournament_10  2014-01-15  2014-02-08   \n",
      "12   tournament_10  2014-01-15  2014-02-08   \n",
      "13   tournament_10  2014-01-15  2014-02-08   \n",
      "14   tournament_10  2014-01-15  2014-02-08   \n",
      "15   tournament_10  2014-01-15  2014-02-08   \n",
      "16   tournament_10  2014-01-15  2014-02-08   \n",
      "17   tournament_10  2014-01-15  2014-02-08   \n",
      "18   tournament_10  2014-01-15  2014-02-08   \n",
      "19   tournament_10  2014-01-15  2014-02-08   \n",
      "20   tournament_10  2014-01-15  2014-02-08   \n",
      "21  tournament_100  2014-08-29  2014-09-22   \n",
      "22  tournament_100  2014-08-29  2014-09-22   \n",
      "23  tournament_100  2014-08-29  2014-09-22   \n",
      "24  tournament_100  2014-08-29  2014-09-22   \n",
      "25  tournament_100  2014-08-29  2014-09-22   \n",
      "26  tournament_100  2014-08-29  2014-09-22   \n",
      "27  tournament_100  2014-08-29  2014-09-22   \n",
      "28  tournament_100  2014-08-29  2014-09-22   \n",
      "29  tournament_100  2014-08-29  2014-09-22   \n",
      "30  tournament_100  2014-08-29  2014-09-22   \n",
      "31  tournament_100  2014-08-29  2014-09-22   \n",
      "32  tournament_100  2014-08-29  2014-09-22   \n",
      "\n",
      "                                                games  tours time_control  \n",
      "0   [{'white': '贾叶珍', 'black': '范辰妮', 'date': '201...      9        rapid  \n",
      "1   [{'white': '曹灵缨', 'black': '陆桂姐', 'date': '201...      9        rapid  \n",
      "2   [{'white': '刘家坚', 'black': '沈岚鸿', 'date': '201...      9        rapid  \n",
      "3   [{'white': '沈岚鸿', 'black': '李文子', 'date': '201...      9        rapid  \n",
      "4   [{'white': '范存妞', 'black': '沈岚鸿', 'date': '201...      9        rapid  \n",
      "5   [{'white': '沈岚鸿', 'black': '毛均承', 'date': '201...      9        rapid  \n",
      "6   [{'white': '梁良', 'black': '沈岚鸿', 'date': '2014...      9        rapid  \n",
      "7   [{'white': '沈岚鸿', 'black': '李守超', 'date': '201...      9        rapid  \n",
      "8   [{'white': '张志琼', 'black': '沈岚鸿', 'date': '201...      9        rapid  \n",
      "9   [{'white': 'Liang, Qing', 'black': 'Tian, Xion...     12        rapid  \n",
      "10  [{'white': 'Wang, Jianyao', 'black': 'Wei, Min...     12        rapid  \n",
      "11  [{'white': 'Li, Minkang', 'black': 'Wang, Jian...     12        rapid  \n",
      "12  [{'white': 'Wang, Jianyao', 'black': 'Huang, M...     12        rapid  \n",
      "13  [{'white': 'Xu, Xiaozhi', 'black': 'Wang, Jian...     12        rapid  \n",
      "14  [{'white': 'Wang, Jianyao', 'black': 'Jiang, D...     12        rapid  \n",
      "15  [{'white': 'Huang, Mengli', 'black': 'Chen, Yu...     12        rapid  \n",
      "16  [{'white': 'Liang, Shujun', 'black': 'Huang, M...     12        rapid  \n",
      "17  [{'white': 'Huang, Mengli', 'black': 'Song, Ze...     12        rapid  \n",
      "18  [{'white': 'Wang, Dian', 'black': 'Huang, Meng...     12        rapid  \n",
      "19  [{'white': 'Huang, Mengli', 'black': 'Zhu, Qin...     12        rapid  \n",
      "20  [{'white': 'Li, Hai', 'black': 'Huang, Mengli'...     12        rapid  \n",
      "21  [{'white': '郝华琳', 'black': '王剑妹', 'date': '201...     12      classic  \n",
      "22  [{'white': '李秀寿', 'black': '蔡玉雪', 'date': '201...     12      classic  \n",
      "23  [{'white': '刘碧艳', 'black': '彭国', 'date': '2014...     12      classic  \n",
      "24  [{'white': '章泽', 'black': '梁梅强', 'date': '2014...     12      classic  \n",
      "25  [{'white': '梁梅强', 'black': '彭国', 'date': '2014...     12      classic  \n",
      "26  [{'white': '赵晋耕', 'black': '梁梅强', 'date': '201...     12      classic  \n",
      "27  [{'white': '梁梅强', 'black': '王剑妹', 'date': '201...     12      classic  \n",
      "28  [{'white': '王剑妹', 'black': '贾烨广', 'date': '201...     12      classic  \n",
      "29  [{'white': '贾烨广', 'black': '李利平', 'date': '201...     12      classic  \n",
      "30  [{'white': '李利平', 'black': '梁梅强', 'date': '201...     12      classic  \n",
      "31  [{'white': '梁梅强', 'black': '顾加军', 'date': '201...     12      classic  \n",
      "32  [{'white': '顾加军', 'black': '孙义敏', 'date': '201...     12      classic  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Base URL for the JSON files\n",
    "base_url = 'https://github.com/SunilGorantla/QT_Batch_0011/raw/main/Machine_Learning/datasets/chess/train'\n",
    "\n",
    "# Step 2: List of JSON filenames to be read\n",
    "file_names = [\n",
    "    'tournament_1.json',\n",
    "    'tournament_10.json',\n",
    "    'tournament_100.json'\n",
    "]\n",
    "\n",
    "# Step 3: Initialize an empty list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Step 4: Loop through the file names, read each file, and append to the list\n",
    "for file_name in file_names:\n",
    "    file_url = f\"{base_url}/{file_name}\"\n",
    "    df = pd.read_json(file_url)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Step 5: Concatenate all DataFrames into a single DataFrame\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Step 6: Display the first few rows of the combined DataFrame\n",
    "print(combined_df.head(100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "260e2039-3ba4-42eb-be45-08f326ca0d22",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m     dfs\u001b[38;5;241m.\u001b[39mappend(df)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Step 6: Concatenate all DataFrames into a single DataFrame\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m combined_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(dfs, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Step 7: Display the first few rows of the combined DataFrame\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(combined_df\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:382\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 382\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[0;32m    383\u001b[0m     objs,\n\u001b[0;32m    384\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m    385\u001b[0m     ignore_index\u001b[38;5;241m=\u001b[39mignore_index,\n\u001b[0;32m    386\u001b[0m     join\u001b[38;5;241m=\u001b[39mjoin,\n\u001b[0;32m    387\u001b[0m     keys\u001b[38;5;241m=\u001b[39mkeys,\n\u001b[0;32m    388\u001b[0m     levels\u001b[38;5;241m=\u001b[39mlevels,\n\u001b[0;32m    389\u001b[0m     names\u001b[38;5;241m=\u001b[39mnames,\n\u001b[0;32m    390\u001b[0m     verify_integrity\u001b[38;5;241m=\u001b[39mverify_integrity,\n\u001b[0;32m    391\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    392\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    393\u001b[0m )\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:445\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify_integrity \u001b[38;5;241m=\u001b[39m verify_integrity\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;241m=\u001b[39m copy\n\u001b[1;32m--> 445\u001b[0m objs, keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clean_keys_and_objs(objs, keys)\n\u001b[0;32m    447\u001b[0m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[0;32m    448\u001b[0m ndims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ndims(objs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:507\u001b[0m, in \u001b[0;36m_Concatenator._clean_keys_and_objs\u001b[1;34m(self, objs, keys)\u001b[0m\n\u001b[0;32m    504\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[0;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs_list) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 507\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    510\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(com\u001b[38;5;241m.\u001b[39mnot_none(\u001b[38;5;241m*\u001b[39mobjs_list))\n",
      "\u001b[1;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Step 1: Specify the URL to the GitHub directory\n",
    "base_url = 'https://github.com/SunilGorantla/QT_Batch_0011/raw/main/Machine_Learning/datasets/chess/train'\n",
    "directory_url = 'https://github.com/SunilGorantla/QT_Batch_0011/tree/main/Machine_Learning/datasets/chess/train'\n",
    "\n",
    "# Step 2: Get the directory page content\n",
    "response = requests.get(directory_url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Step 3: Extract all JSON file links from the page\n",
    "json_files = []\n",
    "for link in soup.find_all('a', href=True):\n",
    "    if link['href'].endswith('.json'):\n",
    "        file_url = base_url + '/' + link['href'].split('/')[-1]\n",
    "        json_files.append(file_url)\n",
    "\n",
    "# Step 4: Initialize an empty list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Step 5: Loop through the list of JSON file URLs, read them, and append to the list\n",
    "for file_url in json_files:\n",
    "    df = pd.read_json(file_url)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Step 6: Concatenate all DataFrames into a single DataFrame\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Step 7: Display the first few rows of the combined DataFrame\n",
    "print(combined_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21bab8e3-6e57-43d5-866a-def10f15610b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           name  start_date    end_date  \\\n",
      "0  tournament_1  2014-01-08  2014-01-17   \n",
      "1  tournament_1  2014-01-08  2014-01-17   \n",
      "2  tournament_1  2014-01-08  2014-01-17   \n",
      "3  tournament_1  2014-01-08  2014-01-17   \n",
      "4  tournament_1  2014-01-08  2014-01-17   \n",
      "\n",
      "                                               games  tours time_control  \n",
      "0  [{'white': '贾叶珍', 'black': '范辰妮', 'date': '201...      9        rapid  \n",
      "1  [{'white': '曹灵缨', 'black': '陆桂姐', 'date': '201...      9        rapid  \n",
      "2  [{'white': '刘家坚', 'black': '沈岚鸿', 'date': '201...      9        rapid  \n",
      "3  [{'white': '沈岚鸿', 'black': '李文子', 'date': '201...      9        rapid  \n",
      "4  [{'white': '范存妞', 'black': '沈岚鸿', 'date': '201...      9        rapid  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Step 1: Set the directory URL where the JSON files are located\n",
    "directory_url = 'https://github.com/SunilGorantla/QT_Batch_0011/tree/main/Machine_Learning/datasets/chess/train'\n",
    "base_url = 'https://github.com/SunilGorantla/QT_Batch_0011/raw/main/Machine_Learning/datasets/chess/train'\n",
    "\n",
    "# Step 2: Get the HTML content of the directory page\n",
    "response = requests.get(directory_url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Step 3: Extract all JSON file links from the page\n",
    "json_files = []\n",
    "for link in soup.find_all('a', href=True):\n",
    "    if link['href'].endswith('.json'):\n",
    "        json_files.append(link['href'].split('/')[-1])\n",
    "\n",
    "# Step 4: Initialize an empty list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Step 5: Loop through the list of JSON filenames, read them, and append to the list\n",
    "for json_file in json_files:\n",
    "    file_url = f\"{base_url}/{json_file}\"\n",
    "    df = pd.read_json(file_url)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Step 6: Concatenate all DataFrames into a single DataFrame\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Step 7: Display the first few rows of the combined DataFrame\n",
    "print(combined_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ec64a5b-f22c-492f-ae37-3c6217bef482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame has been saved to F:\\jupyter\\json1.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming final_df is already created and contains data\n",
    "\n",
    "# Define the file path where you want to save the CSV file\n",
    "file_path = r'F:\\jupyter\\json1.csv'\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "combined_df.to_csv(file_path, index=False)\n",
    "\n",
    "print(f\"DataFrame has been saved to {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e1adbb02-5e33-446d-aed9-3c7f50990f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tournament_1.json', 'tournament_1.json', 'tournament_10.json', 'tournament_10.json', 'tournament_100.json', 'tournament_100.json', 'tournament_101.json', 'tournament_101.json', 'tournament_102.json', 'tournament_102.json', 'tournament_103.json', 'tournament_103.json', 'tournament_104.json', 'tournament_104.json', 'tournament_105.json', 'tournament_105.json', 'tournament_106.json', 'tournament_106.json', 'tournament_107.json', 'tournament_107.json', 'tournament_108.json', 'tournament_108.json', 'tournament_109.json', 'tournament_109.json', 'tournament_11.json', 'tournament_11.json', 'tournament_110.json', 'tournament_110.json', 'tournament_111.json', 'tournament_111.json', 'tournament_112.json', 'tournament_112.json', 'tournament_113.json', 'tournament_113.json', 'tournament_114.json', 'tournament_114.json', 'tournament_115.json', 'tournament_115.json', 'tournament_116.json', 'tournament_116.json', 'tournament_117.json', 'tournament_117.json', 'tournament_118.json', 'tournament_118.json', 'tournament_119.json', 'tournament_119.json', 'tournament_12.json', 'tournament_12.json', 'tournament_120.json', 'tournament_120.json', 'tournament_121.json', 'tournament_121.json', 'tournament_122.json', 'tournament_122.json', 'tournament_123.json', 'tournament_123.json', 'tournament_124.json', 'tournament_124.json', 'tournament_125.json', 'tournament_125.json', 'tournament_126.json', 'tournament_126.json', 'tournament_127.json', 'tournament_127.json', 'tournament_128.json', 'tournament_128.json', 'tournament_129.json', 'tournament_129.json', 'tournament_13.json', 'tournament_13.json', 'tournament_130.json', 'tournament_130.json', 'tournament_131.json', 'tournament_131.json', 'tournament_132.json', 'tournament_132.json', 'tournament_133.json', 'tournament_133.json', 'tournament_134.json', 'tournament_134.json', 'tournament_135.json', 'tournament_135.json', 'tournament_136.json', 'tournament_136.json', 'tournament_137.json', 'tournament_137.json', 'tournament_138.json', 'tournament_138.json', 'tournament_139.json', 'tournament_139.json', 'tournament_14.json', 'tournament_14.json', 'tournament_140.json', 'tournament_140.json', 'tournament_141.json', 'tournament_141.json', 'tournament_142.json', 'tournament_142.json', 'tournament_143.json', 'tournament_143.json', 'tournament_144.json', 'tournament_144.json', 'tournament_145.json', 'tournament_145.json', 'tournament_146.json', 'tournament_146.json', 'tournament_147.json', 'tournament_147.json', 'tournament_148.json', 'tournament_148.json', 'tournament_149.json', 'tournament_149.json', 'tournament_15.json', 'tournament_15.json', 'tournament_150.json', 'tournament_150.json', 'tournament_151.json', 'tournament_151.json', 'tournament_152.json', 'tournament_152.json', 'tournament_153.json', 'tournament_153.json', 'tournament_154.json', 'tournament_154.json', 'tournament_155.json', 'tournament_155.json', 'tournament_156.json', 'tournament_156.json', 'tournament_157.json', 'tournament_157.json', 'tournament_158.json', 'tournament_158.json', 'tournament_159.json', 'tournament_159.json', 'tournament_16.json', 'tournament_16.json', 'tournament_160.json', 'tournament_160.json', 'tournament_161.json', 'tournament_161.json', 'tournament_162.json', 'tournament_162.json', 'tournament_163.json', 'tournament_163.json', 'tournament_164.json', 'tournament_164.json', 'tournament_165.json', 'tournament_165.json', 'tournament_166.json', 'tournament_166.json', 'tournament_167.json', 'tournament_167.json', 'tournament_168.json', 'tournament_168.json', 'tournament_169.json', 'tournament_169.json', 'tournament_17.json', 'tournament_17.json', 'tournament_170.json', 'tournament_170.json', 'tournament_171.json', 'tournament_171.json', 'tournament_172.json', 'tournament_172.json', 'tournament_173.json', 'tournament_173.json', 'tournament_174.json', 'tournament_174.json', 'tournament_175.json', 'tournament_175.json', 'tournament_176.json', 'tournament_176.json', 'tournament_177.json', 'tournament_177.json', 'tournament_178.json', 'tournament_178.json', 'tournament_179.json', 'tournament_179.json', 'tournament_18.json', 'tournament_18.json', 'tournament_180.json', 'tournament_180.json', 'tournament_181.json', 'tournament_181.json', 'tournament_182.json', 'tournament_182.json', 'tournament_183.json', 'tournament_183.json', 'tournament_184.json', 'tournament_184.json', 'tournament_185.json', 'tournament_185.json', 'tournament_186.json', 'tournament_186.json', 'tournament_187.json', 'tournament_187.json', 'tournament_188.json', 'tournament_188.json', 'tournament_189.json', 'tournament_189.json']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Step 1: Set the URL of the GitHub directory\n",
    "directory_url = 'https://github.com/SunilGorantla/QT_Batch_0011/tree/main/Machine_Learning/datasets/chess/train'\n",
    "\n",
    "# Step 2: Send a request to the GitHub directory page\n",
    "response = requests.get(directory_url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Step 3: Find all links on the page\n",
    "file_names = []\n",
    "for link in soup.find_all('a', href=True):\n",
    "    href = link['href']\n",
    "    if href.endswith('.json'):  # Check if the link is a JSON file\n",
    "        file_name = href.split('/')[-1]  # Extract the file name from the URL\n",
    "        file_names.append(file_name)\n",
    "\n",
    "# Step 4: Print the list of JSON filenames\n",
    "print(file_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e274f884-c055-4d78-9995-2c6177fdea6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               name  start_date    end_date  \\\n",
      "0      tournament_1  2014-01-08  2014-01-17   \n",
      "1      tournament_1  2014-01-08  2014-01-17   \n",
      "2      tournament_1  2014-01-08  2014-01-17   \n",
      "3      tournament_1  2014-01-08  2014-01-17   \n",
      "4      tournament_1  2014-01-08  2014-01-17   \n",
      "..              ...         ...         ...   \n",
      "995  tournament_145  2015-01-24  2015-02-05   \n",
      "996  tournament_145  2015-01-24  2015-02-05   \n",
      "997  tournament_145  2015-01-24  2015-02-05   \n",
      "998  tournament_145  2015-01-24  2015-02-05   \n",
      "999  tournament_145  2015-01-24  2015-02-05   \n",
      "\n",
      "                                                 games  tours time_control  \n",
      "0    [{'white': '贾叶珍', 'black': '范辰妮', 'date': '201...      9        rapid  \n",
      "1    [{'white': '曹灵缨', 'black': '陆桂姐', 'date': '201...      9        rapid  \n",
      "2    [{'white': '刘家坚', 'black': '沈岚鸿', 'date': '201...      9        rapid  \n",
      "3    [{'white': '沈岚鸿', 'black': '李文子', 'date': '201...      9        rapid  \n",
      "4    [{'white': '范存妞', 'black': '沈岚鸿', 'date': '201...      9        rapid  \n",
      "..                                                 ...    ...          ...  \n",
      "995  [{'white': 'Cao, Tingyun', 'black': 'Duan, Lij...     12      classic  \n",
      "996  [{'white': 'Liang, Sipei', 'black': 'Yang, Sha...     12      classic  \n",
      "997  [{'white': 'Yang, Peicha', 'black': 'Liang, Si...     12      classic  \n",
      "998  [{'white': 'Liang, Sipei', 'black': 'Qi, Huizh...     12      classic  \n",
      "999  [{'white': 'Wang, Jianming', 'black': 'Liang, ...     12      classic  \n",
      "\n",
      "[1000 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Base URL for the JSON files\n",
    "base_url = 'https://github.com/SunilGorantla/QT_Batch_0011/raw/main/Machine_Learning/datasets/chess/train'\n",
    "\n",
    "# Step 2: List of JSON filenames to be read\n",
    "file_names = [\n",
    "   'tournament_1.json', 'tournament_1.json', 'tournament_10.json', 'tournament_10.json', 'tournament_100.json', 'tournament_100.json', \n",
    "    'tournament_101.json', 'tournament_101.json', 'tournament_102.json', 'tournament_102.json', 'tournament_103.json', 'tournament_103.json',\n",
    "    'tournament_104.json', 'tournament_104.json', 'tournament_105.json', 'tournament_105.json', 'tournament_106.json', 'tournament_106.json', \n",
    "    'tournament_107.json', 'tournament_107.json', 'tournament_108.json', 'tournament_108.json', 'tournament_109.json', 'tournament_109.json',\n",
    "    'tournament_11.json', 'tournament_11.json', 'tournament_110.json', 'tournament_110.json', 'tournament_111.json', 'tournament_111.json',\n",
    "    'tournament_112.json', 'tournament_112.json', 'tournament_113.json', 'tournament_113.json', 'tournament_114.json', 'tournament_114.json', \n",
    "    'tournament_115.json', 'tournament_115.json', 'tournament_116.json', 'tournament_116.json', 'tournament_117.json', 'tournament_117.json',\n",
    "    'tournament_118.json', 'tournament_118.json', 'tournament_119.json', 'tournament_119.json', 'tournament_12.json', 'tournament_12.json',\n",
    "    'tournament_120.json', 'tournament_120.json', 'tournament_121.json', 'tournament_121.json', 'tournament_122.json', 'tournament_122.json', \n",
    "    'tournament_123.json', 'tournament_123.json', 'tournament_124.json', 'tournament_124.json', 'tournament_125.json', 'tournament_125.json', \n",
    "    'tournament_126.json', 'tournament_126.json', 'tournament_127.json', 'tournament_127.json', 'tournament_128.json', 'tournament_128.json', \n",
    "    'tournament_129.json', 'tournament_129.json', 'tournament_13.json', 'tournament_13.json', 'tournament_130.json', 'tournament_130.json', \n",
    "    'tournament_131.json', 'tournament_131.json', 'tournament_132.json', 'tournament_132.json', 'tournament_133.json', 'tournament_133.json',\n",
    "    'tournament_134.json', 'tournament_134.json', 'tournament_135.json', 'tournament_135.json', 'tournament_136.json', 'tournament_136.json',\n",
    "    'tournament_137.json', 'tournament_137.json', 'tournament_138.json', 'tournament_138.json', 'tournament_139.json', 'tournament_139.json',\n",
    "    'tournament_14.json', 'tournament_14.json', 'tournament_140.json', 'tournament_140.json', 'tournament_141.json', 'tournament_141.json',\n",
    "    'tournament_142.json', 'tournament_142.json', 'tournament_143.json', 'tournament_143.json', 'tournament_144.json', 'tournament_144.json', \n",
    "    'tournament_145.json', 'tournament_145.json', 'tournament_146.json', 'tournament_146.json', 'tournament_147.json', 'tournament_147.json',\n",
    "    'tournament_148.json', 'tournament_148.json', 'tournament_149.json', 'tournament_149.json', 'tournament_15.json', 'tournament_15.json',\n",
    "    'tournament_150.json', 'tournament_150.json', 'tournament_151.json', 'tournament_151.json', 'tournament_152.json', 'tournament_152.json',\n",
    "    'tournament_153.json', 'tournament_153.json', 'tournament_154.json', 'tournament_154.json', 'tournament_155.json', 'tournament_155.json', \n",
    "    'tournament_156.json', 'tournament_156.json', 'tournament_157.json', 'tournament_157.json', 'tournament_158.json', 'tournament_158.json', \n",
    "    'tournament_159.json', 'tournament_159.json', 'tournament_16.json', 'tournament_16.json', 'tournament_160.json', 'tournament_160.json',\n",
    "    'tournament_161.json', 'tournament_161.json', 'tournament_162.json', 'tournament_162.json', 'tournament_163.json', 'tournament_163.json',\n",
    "    'tournament_164.json', 'tournament_164.json', 'tournament_165.json', 'tournament_165.json', 'tournament_166.json', 'tournament_166.json', \n",
    "    'tournament_167.json', 'tournament_167.json', 'tournament_168.json', 'tournament_168.json', 'tournament_169.json', 'tournament_169.json', \n",
    "    'tournament_17.json', 'tournament_17.json', 'tournament_170.json', 'tournament_170.json', 'tournament_171.json', 'tournament_171.json', \n",
    "    'tournament_172.json', 'tournament_172.json', 'tournament_173.json', 'tournament_173.json', 'tournament_174.json', 'tournament_174.json',\n",
    "    'tournament_175.json', 'tournament_175.json', 'tournament_176.json', 'tournament_176.json', 'tournament_177.json', 'tournament_177.json',\n",
    "    'tournament_178.json', 'tournament_178.json', 'tournament_179.json', 'tournament_179.json', 'tournament_18.json', 'tournament_18.json',\n",
    "    'tournament_180.json', 'tournament_180.json', 'tournament_181.json', 'tournament_181.json', 'tournament_182.json', 'tournament_182.json',\n",
    "    'tournament_183.json', 'tournament_183.json', 'tournament_184.json', 'tournament_184.json', 'tournament_185.json', 'tournament_185.json',\n",
    "    'tournament_186.json', 'tournament_186.json', 'tournament_187.json','tournament_189.json', 'tournament_189.json','tournament_187.json',\n",
    "     'tournament_188.json', 'tournament_188.json', \n",
    "]\n",
    "\n",
    "# Step 3: Initialize an empty list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Step 4: Loop through the file names, read each file, and append to the list\n",
    "for file_name in file_names:\n",
    "    file_url = f\"{base_url}/{file_name}\"\n",
    "    df = pd.read_json(file_url)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Step 5: Concatenate all DataFrames into a single DataFrame\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Step 6: Display the first few rows of the combined DataFrame\n",
    "print(combined_df.head(1000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "79558f81-cd7a-49bc-851c-6f954e5055e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: polars in c:\\users\\chaitanya\\anaconda3\\lib\\site-packages (1.5.0)\n",
      "Requirement already satisfied: requests in c:\\users\\chaitanya\\anaconda3\\lib\\site-packages (2.32.2)\n",
      "Requirement already satisfied: polars in c:\\users\\chaitanya\\anaconda3\\lib\\site-packages (1.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\chaitanya\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\chaitanya\\anaconda3\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\chaitanya\\anaconda3\\lib\\site-packages (from requests) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chaitanya\\anaconda3\\lib\\site-packages (from requests) (2024.7.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install polars\n",
    "!pip install requests polars\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0cc2d7b1-2787-4d37-ba08-dc28d18cdd49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               name  start_date    end_date  \\\n",
      "0      tournament_1  2014-01-08  2014-01-17   \n",
      "1      tournament_1  2014-01-08  2014-01-17   \n",
      "2      tournament_1  2014-01-08  2014-01-17   \n",
      "3      tournament_1  2014-01-08  2014-01-17   \n",
      "4      tournament_1  2014-01-08  2014-01-17   \n",
      "..              ...         ...         ...   \n",
      "125  tournament_103  2014-09-08  2014-09-08   \n",
      "126  tournament_103  2014-09-08  2014-09-08   \n",
      "127  tournament_103  2014-09-08  2014-09-08   \n",
      "128  tournament_103  2014-09-08  2014-09-08   \n",
      "129  tournament_103  2014-09-08  2014-09-08   \n",
      "\n",
      "                                                 games  tours time_control  \n",
      "0    [{'white': '贾叶珍', 'black': '范辰妮', 'date': '201...      9        rapid  \n",
      "1    [{'white': '曹灵缨', 'black': '陆桂姐', 'date': '201...      9        rapid  \n",
      "2    [{'white': '刘家坚', 'black': '沈岚鸿', 'date': '201...      9        rapid  \n",
      "3    [{'white': '沈岚鸿', 'black': '李文子', 'date': '201...      9        rapid  \n",
      "4    [{'white': '范存妞', 'black': '沈岚鸿', 'date': '201...      9        rapid  \n",
      "..                                                 ...    ...          ...  \n",
      "125  [{'white': '秦志', 'black': '冯燕家', 'date': '2014...     12      classic  \n",
      "126  [{'white': '王小生', 'black': '范元', 'date': '2014...     12      classic  \n",
      "127  [{'white': '范元', 'black': '林康俊', 'date': '2014...     12      classic  \n",
      "128  [{'white': '王小生', 'black': '杨灵', 'date': '2014...     12      classic  \n",
      "129  [{'white': '杨灵', 'black': '谢亮良', 'date': '2014...     12      classic  \n",
      "\n",
      "[130 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Base URL for the JSON files\n",
    "base_url = 'https://github.com/SunilGorantla/QT_Batch_0011/raw/main/Machine_Learning/datasets/chess/train'\n",
    "\n",
    "# Step 2: List of JSON filenames to be read\n",
    "file_names = [\n",
    "     'tournament_1.json', 'tournament_1.json', 'tournament_10.json', 'tournament_10.json', 'tournament_100.json', 'tournament_100.json', \n",
    "    'tournament_101.json', 'tournament_101.json', 'tournament_102.json', 'tournament_102.json', 'tournament_103.json', 'tournament_103.json',\n",
    "]\n",
    "\n",
    "# Step 3: Initialize an empty list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Step 4: Loop through the file names, read each file, and append to the list\n",
    "for file_name in file_names:\n",
    "    file_url = f\"{base_url}/{file_name}\"\n",
    "    df = pd.read_json(file_url)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Step 5: Concatenate all DataFrames into a single DataFrame\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Step 6: Display the first few rows of the combined DataFrame\n",
    "print(combined_df.head(1000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d99e8bc8-3fe6-4f7c-8d6d-55d0bbaa0f41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9\n",
       "Name: tours, dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "combined_df['tours'].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5545834f-9a31-468a-a7e0-b6b2b157514b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['name', 'start_date', 'end_date', 'games', 'tours', 'time_control'], dtype='object')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "42e8cb5f-760d-407c-8e96-543d0f953cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Names and Values for Record at Index 0\n",
      "name: tournament_1\n",
      "start_date: 2014-01-08\n",
      "end_date: 2014-01-17\n",
      "games: [{'white': '贾叶珍', 'black': '范辰妮', 'date': '2014-01-08', 'result': 0.5, 'id': 'tournament_1_1'}, {'white': '吕亚光', 'black': '李嘉爵', 'date': '2014-01-08', 'result': 0.5, 'id': 'tournament_1_2'}, {'white': '刘奇喜', 'black': '刘晓鹏', 'date': '2014-01-08', 'result': 0.5, 'id': 'tournament_1_3'}, {'white': '陆桂姐', 'black': '郑新聪', 'date': '2014-01-08', 'result': 1, 'id': 'tournament_1_4'}, {'white': '李汶玲', 'black': '叶天英', 'date': '2014-01-08', 'result': 0.5, 'id': 'tournament_1_5'}, {'white': '薛冠', 'black': '杨钰', 'date': '2014-01-08', 'result': 0.5, 'id': 'tournament_1_6'}, {'white': '冯燕家', 'black': '曹灵缨', 'date': '2014-01-08', 'result': 0, 'id': 'tournament_1_7'}, {'white': '刘家坚', 'black': '齐慧智', 'date': '2014-01-08', 'result': 1, 'id': 'tournament_1_8'}, {'white': '张志琼', 'black': '吴秋', 'date': '2014-01-08', 'result': 1, 'id': 'tournament_1_9'}, {'white': '徐先广', 'black': '吴昱明', 'date': '2014-01-08', 'result': 1, 'id': 'tournament_1_10'}, {'white': '杨佩义', 'black': '王由航', 'date': '2014-01-08', 'result': 0, 'id': 'tournament_1_11'}, {'white': '王永赟', 'black': '方东', 'date': '2014-01-08', 'result': 0.5, 'id': 'tournament_1_12'}, {'white': '刘宇福', 'black': '朱有荣', 'date': '2014-01-08', 'result': 1, 'id': 'tournament_1_13'}, {'white': '杨莎强', 'black': '余冬春', 'date': '2014-01-08', 'result': 0.5, 'id': 'tournament_1_14'}, {'white': '孟芳全', 'black': '阎斯钧', 'date': '2014-01-08', 'result': 0.5, 'id': 'tournament_1_15'}, {'white': '钟弘存', 'black': '张半植', 'date': '2014-01-08', 'result': 0.5, 'id': 'tournament_1_16'}, {'white': '范存妞', 'black': '何建芝', 'date': '2014-01-08', 'result': 1, 'id': 'tournament_1_17'}, {'white': '李琳华', 'black': '毛心磊', 'date': '2014-01-08', 'result': 0, 'id': 'tournament_1_18'}, {'white': '袁小昆', 'black': '董玉波', 'date': '2014-01-08', 'result': 0.5, 'id': 'tournament_1_19'}, {'white': '李文子', 'black': '何驿艳', 'date': '2014-01-08', 'result': 1, 'id': 'tournament_1_20'}, {'white': '刘先', 'black': '梁扬', 'date': '2014-01-08', 'result': 1, 'id': 'tournament_1_21'}, {'white': '杨燕波', 'black': '袁宪萍', 'date': '2014-01-08', 'result': 0.5, 'id': 'tournament_1_22'}, {'white': '陈思刚', 'black': '刘星梅', 'date': '2014-01-08', 'result': 0.5, 'id': 'tournament_1_23'}, {'white': '张延营', 'black': '张燕', 'date': '2014-01-08', 'result': 1, 'id': 'tournament_1_24'}, {'white': '张安甜', 'black': '张木兴', 'date': '2014-01-08', 'result': 1, 'id': 'tournament_1_25'}, {'white': '李松江', 'black': '王千迅', 'date': '2014-01-08', 'result': 1, 'id': 'tournament_1_26'}, {'white': '梁良', 'black': '殷小', 'date': '2014-01-08', 'result': 1, 'id': 'tournament_1_27'}, {'white': '董海非', 'black': '魏兴', 'date': '2014-01-08', 'result': 0.5, 'id': 'tournament_1_28'}, {'white': '毛均承', 'black': '彭国', 'date': '2014-01-08', 'result': 0.5, 'id': 'tournament_1_29'}, {'white': '李守超', 'black': '谢庆麟', 'date': '2014-01-08', 'result': 1, 'id': 'tournament_1_30'}, {'white': '王剑铭', 'black': '陈音亮', 'date': '2014-01-08', 'result': 1, 'id': 'tournament_1_31'}, {'white': '杨承', 'black': '沈岚鸿', 'date': '2014-01-08', 'result': 0, 'id': 'tournament_1_32'}, {'white': '张家懿', 'black': '李巧芸', 'date': '2014-01-08', 'result': 0, 'id': 'tournament_1_33'}]\n",
      "tours: 9\n",
      "time_control: rapid\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Base URL for the JSON files\n",
    "base_url = 'https://github.com/SunilGorantla/QT_Batch_0011/raw/main/Machine_Learning/datasets/chess/train'\n",
    "\n",
    "# Step 2: List of JSON filenames to be read\n",
    "file_names = [\n",
    "    'tournament_1.json', 'tournament_1.json', 'tournament_10.json', 'tournament_10.json', 'tournament_100.json', 'tournament_100.json', \n",
    "    'tournament_101.json', 'tournament_101.json', 'tournament_102.json', 'tournament_102.json', 'tournament_103.json', 'tournament_103.json',\n",
    "]\n",
    "\n",
    "# Step 3: Initialize an empty list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Step 4: Loop through the file names, read each file, and append to the list\n",
    "for file_name in file_names:\n",
    "    file_url = f\"{base_url}/{file_name}\"\n",
    "    df = pd.read_json(file_url)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Step 5: Concatenate all DataFrames into a single DataFrame\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Step 6: Retrieve and print one record from the DataFrame\n",
    "record_index = 0  # Index of the record you want to retrieve\n",
    "record = combined_df.iloc[record_index]  # Retrieve the record\n",
    "\n",
    "# Print the column names and values\n",
    "print(\"Column Names and Values for Record at Index\", record_index)\n",
    "for column_name, value in record.items():\n",
    "    print(f\"{column_name}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4307a4b1-bdc6-4516-81d7-aa1cc1e5738f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [{'white': '贾叶珍', 'black': '范辰妮', 'date': '201...\n",
       "Name: games, dtype: object"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df['games'].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4bc833d8-64bf-477d-ad73-da5c635360dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           name  start_date    end_date  tours time_control white black  \\\n",
      "0  tournament_1  2014-01-08  2014-01-17      9        rapid   贾叶珍   范辰妮   \n",
      "1  tournament_1  2014-01-08  2014-01-17      9        rapid   吕亚光   李嘉爵   \n",
      "2  tournament_1  2014-01-08  2014-01-17      9        rapid   刘奇喜   刘晓鹏   \n",
      "3  tournament_1  2014-01-08  2014-01-17      9        rapid   陆桂姐   郑新聪   \n",
      "4  tournament_1  2014-01-08  2014-01-17      9        rapid   李汶玲   叶天英   \n",
      "\n",
      "         date  result              id  \n",
      "0  2014-01-08     0.5  tournament_1_1  \n",
      "1  2014-01-08     0.5  tournament_1_2  \n",
      "2  2014-01-08     0.5  tournament_1_3  \n",
      "3  2014-01-08     1.0  tournament_1_4  \n",
      "4  2014-01-08     0.5  tournament_1_5  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Base URL for the JSON files\n",
    "base_url = 'https://github.com/SunilGorantla/QT_Batch_0011/raw/main/Machine_Learning/datasets/chess/train'\n",
    "\n",
    "# Step 2: List of JSON filenames to be read\n",
    "file_names = [\n",
    "    'tournament_1.json', 'tournament_1.json', 'tournament_10.json', 'tournament_10.json', 'tournament_100.json', 'tournament_100.json', \n",
    "    'tournament_101.json', 'tournament_101.json', 'tournament_102.json', 'tournament_102.json', 'tournament_103.json', 'tournament_103.json',\n",
    "]\n",
    "\n",
    "# Step 3: Initialize an empty list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Step 4: Loop through the file names, read each file, and append to the list\n",
    "for file_name in file_names:\n",
    "    file_url = f\"{base_url}/{file_name}\"\n",
    "    df = pd.read_json(file_url)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Step 5: Concatenate all DataFrames into a single DataFrame\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Step 6: Reset index to avoid index-related issues\n",
    "combined_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Step 7: Explode the \"games\" column to separate rows for each game\n",
    "games_df = combined_df.explode('games')\n",
    "\n",
    "# Step 8: Convert the exploded \"games\" column to a DataFrame\n",
    "games_details_df = pd.json_normalize(games_df['games'])\n",
    "\n",
    "# Step 9: Reset index of exploded games DataFrame\n",
    "games_df.reset_index(drop=True, inplace=True)\n",
    "games_details_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Step 10: Concatenate the new games details DataFrame with the original DataFrame\n",
    "combined_df = pd.concat([games_df.drop(columns='games'), games_details_df], axis=1)\n",
    "\n",
    "# Display the new DataFrame structure\n",
    "print(combined_df.head())\n",
    "\n",
    "# Optional: Save the new DataFrame to a CSV file for further analysis\n",
    "combined_df.to_csv('simplified_chess_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "155e3903-b43f-4a66-9f41-f77a2108581d",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "Reindexing only valid with uniquely valued Index objects",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[125], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m games_details_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mjson_normalize(games_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgames\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Step 9: Concatenate the new games details DataFrame with the original DataFrame (excluding the old \"games\" column)\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m combined_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([games_df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgames\u001b[39m\u001b[38;5;124m'\u001b[39m), games_details_df], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Display the new DataFrame structure\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(combined_df\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:395\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    382\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[0;32m    383\u001b[0m     objs,\n\u001b[0;32m    384\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    392\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    393\u001b[0m )\n\u001b[1;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:680\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    678\u001b[0m         obj_labels \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39maxes[\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m ax]\n\u001b[0;32m    679\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m new_labels\u001b[38;5;241m.\u001b[39mequals(obj_labels):\n\u001b[1;32m--> 680\u001b[0m             indexers[ax] \u001b[38;5;241m=\u001b[39m obj_labels\u001b[38;5;241m.\u001b[39mget_indexer(new_labels)\n\u001b[0;32m    682\u001b[0m     mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n\u001b[0;32m    684\u001b[0m new_data \u001b[38;5;241m=\u001b[39m concatenate_managers(\n\u001b[0;32m    685\u001b[0m     mgrs_indexers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnew_axes, concat_axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbm_axis, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[0;32m    686\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3885\u001b[0m, in \u001b[0;36mIndex.get_indexer\u001b[1;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[0;32m   3882\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_method(method, limit, tolerance)\n\u001b[0;32m   3884\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_as_unique:\n\u001b[1;32m-> 3885\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_requires_unique_msg)\n\u001b[0;32m   3887\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   3888\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp)\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: Reindexing only valid with uniquely valued Index objects"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Base URL for the JSON files\n",
    "base_url = 'https://github.com/SunilGorantla/QT_Batch_0011/raw/main/Machine_Learning/datasets/chess/train'\n",
    "\n",
    "# Step 2: List of JSON filenames to be read\n",
    "file_names = [\n",
    "    'tournament_1.json', 'tournament_1.json', 'tournament_10.json', 'tournament_10.json', 'tournament_100.json', 'tournament_100.json', \n",
    "    'tournament_101.json', 'tournament_101.json', 'tournament_102.json', 'tournament_102.json', 'tournament_103.json', 'tournament_103.json',\n",
    "]\n",
    "\n",
    "# Step 3: Initialize an empty list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Step 4: Loop through the file names, read each file, and append to the list\n",
    "for file_name in file_names:\n",
    "    file_url = f\"{base_url}/{file_name}\"\n",
    "    df = pd.read_json(file_url)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Step 5: Concatenate all DataFrames into a single DataFrame\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Step 6: Reset index to avoid index-related issues\n",
    "combined_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Step 7: Explode the \"games\" column to separate rows for each game\n",
    "games_df = combined_df.explode('games')\n",
    "\n",
    "# Step 8: Convert the exploded \"games\" column to a DataFrame\n",
    "games_details_df = pd.json_normalize(games_df['games'])\n",
    "\n",
    "# Step 9: Concatenate the new games details DataFrame with the original DataFrame (excluding the old \"games\" column)\n",
    "combined_df = pd.concat([games_df.drop(columns='games'), games_details_df], axis=1)\n",
    "\n",
    "# Display the new DataFrame structure\n",
    "print(combined_df.head())\n",
    "\n",
    "# Optional: Save the new DataFrame to a CSV file for further analysis\n",
    "combined_df.to_csv('simplified_chess_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d0ab2d25-25c4-4e02-a56c-95032f12bf1f",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "Reindexing only valid with uniquely valued Index objects",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[127], line 39\u001b[0m\n\u001b[0;32m     36\u001b[0m games_details_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mjson_normalize(games_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgames\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Step 10: Concatenate the new games details DataFrame with the original DataFrame (excluding the old \"games\" column)\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m combined_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([games_df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgames\u001b[39m\u001b[38;5;124m'\u001b[39m), games_details_df], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Step 11: Reset index again after concatenation\u001b[39;00m\n\u001b[0;32m     42\u001b[0m combined_df\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:395\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    382\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[0;32m    383\u001b[0m     objs,\n\u001b[0;32m    384\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    392\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    393\u001b[0m )\n\u001b[1;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:680\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    678\u001b[0m         obj_labels \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39maxes[\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m ax]\n\u001b[0;32m    679\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m new_labels\u001b[38;5;241m.\u001b[39mequals(obj_labels):\n\u001b[1;32m--> 680\u001b[0m             indexers[ax] \u001b[38;5;241m=\u001b[39m obj_labels\u001b[38;5;241m.\u001b[39mget_indexer(new_labels)\n\u001b[0;32m    682\u001b[0m     mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n\u001b[0;32m    684\u001b[0m new_data \u001b[38;5;241m=\u001b[39m concatenate_managers(\n\u001b[0;32m    685\u001b[0m     mgrs_indexers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnew_axes, concat_axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbm_axis, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[0;32m    686\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3885\u001b[0m, in \u001b[0;36mIndex.get_indexer\u001b[1;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[0;32m   3882\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_method(method, limit, tolerance)\n\u001b[0;32m   3884\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_as_unique:\n\u001b[1;32m-> 3885\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_requires_unique_msg)\n\u001b[0;32m   3887\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   3888\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp)\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: Reindexing only valid with uniquely valued Index objects"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Base URL for the JSON files\n",
    "base_url = 'https://github.com/SunilGorantla/QT_Batch_0011/raw/main/Machine_Learning/datasets/chess/train'\n",
    "\n",
    "# Step 2: List of JSON filenames to be read\n",
    "file_names = [\n",
    "    'tournament_1.json', 'tournament_1.json', 'tournament_10.json', 'tournament_10.json', 'tournament_100.json', 'tournament_100.json', \n",
    "    'tournament_101.json', 'tournament_101.json', 'tournament_102.json', 'tournament_102.json', 'tournament_103.json', 'tournament_103.json',\n",
    "]\n",
    "\n",
    "# Step 3: Initialize an empty list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Step 4: Loop through the file names, read each file, and append to the list\n",
    "for file_name in file_names:\n",
    "    file_url = f\"{base_url}/{file_name}\"\n",
    "    try:\n",
    "        df = pd.read_json(file_url)\n",
    "        dfs.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_url}: {e}\")\n",
    "\n",
    "# Step 5: Concatenate all DataFrames into a single DataFrame\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Step 6: Reset index to avoid index-related issues\n",
    "combined_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Step 7: Check if the \"games\" column exists and if it contains lists\n",
    "if 'games' in combined_df.columns and combined_df['games'].apply(lambda x: isinstance(x, list)).all():\n",
    "    # Step 8: Explode the \"games\" column to separate rows for each game\n",
    "    games_df = combined_df.explode('games')\n",
    "\n",
    "    # Step 9: Convert the exploded \"games\" column to a DataFrame\n",
    "    games_details_df = pd.json_normalize(games_df['games'])\n",
    "\n",
    "    # Step 10: Concatenate the new games details DataFrame with the original DataFrame (excluding the old \"games\" column)\n",
    "    combined_df = pd.concat([games_df.drop(columns='games'), games_details_df], axis=1)\n",
    "\n",
    "    # Step 11: Reset index again after concatenation\n",
    "    combined_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Display the new DataFrame structure\n",
    "    print(combined_df.head())\n",
    "\n",
    "    # Optional: Save the new DataFrame to a CSV file for further analysis\n",
    "    combined_df.to_csv('simplified_chess_data.csv', index=False)\n",
    "else:\n",
    "    print(\"The 'games' column is missing or does not contain lists.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "472a39bc-f1d4-4965-bb91-977d54114dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the DataFrame: Index(['name', 'start_date', 'end_date', 'games', 'tours', 'time_control'], dtype='object')\n",
      "Sample data in the DataFrame:            name  start_date    end_date  \\\n",
      "0  tournament_1  2014-01-08  2014-01-17   \n",
      "1  tournament_1  2014-01-08  2014-01-17   \n",
      "2  tournament_1  2014-01-08  2014-01-17   \n",
      "3  tournament_1  2014-01-08  2014-01-17   \n",
      "4  tournament_1  2014-01-08  2014-01-17   \n",
      "\n",
      "                                               games  tours time_control  \n",
      "0  [{'white': '贾叶珍', 'black': '范辰妮', 'date': '201...      9        rapid  \n",
      "1  [{'white': '曹灵缨', 'black': '陆桂姐', 'date': '201...      9        rapid  \n",
      "2  [{'white': '刘家坚', 'black': '沈岚鸿', 'date': '201...      9        rapid  \n",
      "3  [{'white': '沈岚鸿', 'black': '李文子', 'date': '201...      9        rapid  \n",
      "4  [{'white': '范存妞', 'black': '沈岚鸿', 'date': '201...      9        rapid  \n",
      "              name  start_date    end_date  tours time_control          white  \\\n",
      "0     tournament_1  2014-01-08  2014-01-17      9        rapid            贾叶珍   \n",
      "1     tournament_1  2014-01-08  2014-01-17      9        rapid            吕亚光   \n",
      "2     tournament_1  2014-01-08  2014-01-17      9        rapid            刘奇喜   \n",
      "3     tournament_1  2014-01-08  2014-01-17      9        rapid            陆桂姐   \n",
      "4     tournament_1  2014-01-08  2014-01-17      9        rapid            李汶玲   \n",
      "..             ...         ...         ...    ...          ...            ...   \n",
      "995  tournament_10  2014-01-15  2014-02-08     12        rapid  Huang, Mengli   \n",
      "996  tournament_10  2014-01-15  2014-02-08     12        rapid    Li, Minkang   \n",
      "997  tournament_10  2014-01-15  2014-02-08     12        rapid  Jiang, Degang   \n",
      "998  tournament_10  2014-01-15  2014-02-08     12        rapid   Liu, Kaiqing   \n",
      "999  tournament_10  2014-01-15  2014-02-08     12        rapid      Wei, Ming   \n",
      "\n",
      "             black        date  result                 id  \n",
      "0              范辰妮  2014-01-08     0.5     tournament_1_1  \n",
      "1              李嘉爵  2014-01-08     0.5     tournament_1_2  \n",
      "2              刘晓鹏  2014-01-08     0.5     tournament_1_3  \n",
      "3              郑新聪  2014-01-08     1.0     tournament_1_4  \n",
      "4              叶天英  2014-01-08     0.5     tournament_1_5  \n",
      "..             ...         ...     ...                ...  \n",
      "995      Wang, Jin  2014-01-23     1.0  tournament_10_102  \n",
      "996  Gao, Xiaochen  2014-01-23     0.5  tournament_10_103  \n",
      "997      Wang, Cai  2014-01-23     0.5  tournament_10_104  \n",
      "998     Chen, Yuyu  2014-01-23     0.0  tournament_10_105  \n",
      "999  Liang, Shujun  2014-01-23     0.5  tournament_10_106  \n",
      "\n",
      "[1000 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Base URL for the JSON files\n",
    "base_url = 'https://github.com/SunilGorantla/QT_Batch_0011/raw/main/Machine_Learning/datasets/chess/train'\n",
    "\n",
    "# Step 2: List of JSON filenames to be read\n",
    "file_names = [\n",
    "    'tournament_1.json', 'tournament_1.json', 'tournament_10.json', 'tournament_10.json', 'tournament_100.json', 'tournament_100.json', \n",
    "    'tournament_101.json', 'tournament_101.json', 'tournament_102.json', 'tournament_102.json', 'tournament_103.json', 'tournament_103.json',\n",
    "]\n",
    "\n",
    "# Step 3: Initialize an empty list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Step 4: Loop through the file names, read each file, and append to the list\n",
    "for file_name in file_names:\n",
    "    file_url = f\"{base_url}/{file_name}\"\n",
    "    try:\n",
    "        df = pd.read_json(file_url)\n",
    "        dfs.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_url}: {e}\")\n",
    "\n",
    "# Step 5: Concatenate all DataFrames into a single DataFrame\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Step 6: Reset index to ensure unique index values\n",
    "combined_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Step 7: Check the structure of the DataFrame\n",
    "print(\"Columns in the DataFrame:\", combined_df.columns)\n",
    "print(\"Sample data in the DataFrame:\", combined_df.head())\n",
    "\n",
    "# Step 8: Handle the 'games' column\n",
    "if 'games' in combined_df.columns:\n",
    "    # Ensure 'games' column contains lists\n",
    "    if combined_df['games'].apply(lambda x: isinstance(x, list)).all():\n",
    "        # Explode the 'games' column to separate rows for each game\n",
    "        games_df = combined_df.explode('games')\n",
    "        \n",
    "        # Reset index after exploding\n",
    "        games_df.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        # Convert the exploded 'games' column to a DataFrame\n",
    "        games_details_df = pd.json_normalize(games_df['games'])\n",
    "\n",
    "        # Concatenate the new games details DataFrame with the original DataFrame (excluding the old 'games' column)\n",
    "        final_df = pd.concat([games_df.drop(columns='games'), games_details_df], axis=1)\n",
    "\n",
    "        # Reset index again after concatenation\n",
    "        final_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        # Display the new DataFrame structure\n",
    "        print(final_df.head(1000))\n",
    "\n",
    "        # Optional: Save the new DataFrame to a CSV file for further analysis\n",
    "        final_df.to_csv('simplified_chess_data.csv', index=False)\n",
    "    else:\n",
    "        print(\"The 'games' column does not contain lists.\")\n",
    "else:\n",
    "    print(\"The 'games' column is missing.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "320f463e-8ae7-4cc6-9f30-53427b8763ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df[\"name\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cd078da7-fdc7-4806-8eba-db6859b559bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the DataFrame: Index(['name', 'start_date', 'end_date', 'games', 'tours', 'time_control'], dtype='object')\n",
      "Sample data in the DataFrame:            name  start_date    end_date  \\\n",
      "0  tournament_1  2014-01-08  2014-01-17   \n",
      "1  tournament_1  2014-01-08  2014-01-17   \n",
      "2  tournament_1  2014-01-08  2014-01-17   \n",
      "3  tournament_1  2014-01-08  2014-01-17   \n",
      "4  tournament_1  2014-01-08  2014-01-17   \n",
      "\n",
      "                                               games  tours time_control  \n",
      "0  [{'white': '贾叶珍', 'black': '范辰妮', 'date': '201...      9        rapid  \n",
      "1  [{'white': '曹灵缨', 'black': '陆桂姐', 'date': '201...      9        rapid  \n",
      "2  [{'white': '刘家坚', 'black': '沈岚鸿', 'date': '201...      9        rapid  \n",
      "3  [{'white': '沈岚鸿', 'black': '李文子', 'date': '201...      9        rapid  \n",
      "4  [{'white': '范存妞', 'black': '沈岚鸿', 'date': '201...      9        rapid  \n",
      "Final DataFrame Structure:\n",
      "           name  start_date    end_date  tours time_control white black  \\\n",
      "0  tournament_1  2014-01-08  2014-01-17      9        rapid   贾叶珍   范辰妮   \n",
      "1  tournament_1  2014-01-08  2014-01-17      9        rapid   吕亚光   李嘉爵   \n",
      "2  tournament_1  2014-01-08  2014-01-17      9        rapid   刘奇喜   刘晓鹏   \n",
      "3  tournament_1  2014-01-08  2014-01-17      9        rapid   陆桂姐   郑新聪   \n",
      "4  tournament_1  2014-01-08  2014-01-17      9        rapid   李汶玲   叶天英   \n",
      "\n",
      "         date  result              id  \n",
      "0  2014-01-08     0.5  tournament_1_1  \n",
      "1  2014-01-08     0.5  tournament_1_2  \n",
      "2  2014-01-08     0.5  tournament_1_3  \n",
      "3  2014-01-08     1.0  tournament_1_4  \n",
      "4  2014-01-08     0.5  tournament_1_5  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Base URL for the JSON files\n",
    "base_url = 'https://github.com/SunilGorantla/QT_Batch_0011/raw/main/Machine_Learning/datasets/chess/train'\n",
    "\n",
    "# Step 2: List of JSON filenames to be read\n",
    "file_names = [\n",
    "    'tournament_1.json', 'tournament_1.json', 'tournament_10.json', 'tournament_10.json', 'tournament_100.json', 'tournament_100.json', \n",
    "    'tournament_101.json', 'tournament_101.json', 'tournament_102.json', 'tournament_102.json', 'tournament_103.json', 'tournament_103.json',\n",
    "]\n",
    "\n",
    "# Step 3: Initialize an empty list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Step 4: Loop through the file names, read each file, and append to the list\n",
    "for file_name in file_names:\n",
    "    file_url = f\"{base_url}/{file_name}\"\n",
    "    try:\n",
    "        df = pd.read_json(file_url)\n",
    "        dfs.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_url}: {e}\")\n",
    "\n",
    "# Step 5: Concatenate all DataFrames into a single DataFrame\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Step 6: Reset index to ensure unique index values\n",
    "combined_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Step 7: Check the structure of the DataFrame\n",
    "print(\"Columns in the DataFrame:\", combined_df.columns)\n",
    "print(\"Sample data in the DataFrame:\", combined_df.head())\n",
    "\n",
    "# Step 8: Handle the 'games' column\n",
    "if 'games' in combined_df.columns:\n",
    "    # Ensure 'games' column contains lists\n",
    "    if combined_df['games'].apply(lambda x: isinstance(x, list)).all():\n",
    "        # Explode the 'games' column to separate rows for each game\n",
    "        games_df = combined_df.explode('games')\n",
    "        \n",
    "        # Reset index after exploding\n",
    "        games_df.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        # Convert the exploded 'games' column to a DataFrame\n",
    "        games_details_df = pd.json_normalize(games_df['games'])\n",
    "\n",
    "        # Concatenate the new games details DataFrame with the original DataFrame (excluding the old 'games' column)\n",
    "        final_df = pd.concat([games_df.drop(columns='games'), games_details_df], axis=1)\n",
    "\n",
    "        # Reset index again after concatenation\n",
    "        final_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        # Display the new DataFrame structure\n",
    "        print(\"Final DataFrame Structure:\")\n",
    "        print(final_df.head())\n",
    "\n",
    "        # Optional: Save the new DataFrame to a CSV file for further analysis\n",
    "        final_df.to_csv('simplified_chess_data.csv', index=False)\n",
    "    else:\n",
    "        print(\"The 'games' column does not contain lists.\")\n",
    "else:\n",
    "    print(\"The 'games' column is missing.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1be86c34-df2b-4cd3-ac42-c2b9d31edb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            name  start_date    end_date  tours time_control white black  \\\n",
      "0   tournament_1  2014-01-08  2014-01-17      9        rapid   贾叶珍   范辰妮   \n",
      "1   tournament_1  2014-01-08  2014-01-17      9        rapid   吕亚光   李嘉爵   \n",
      "2   tournament_1  2014-01-08  2014-01-17      9        rapid   刘奇喜   刘晓鹏   \n",
      "3   tournament_1  2014-01-08  2014-01-17      9        rapid   陆桂姐   郑新聪   \n",
      "4   tournament_1  2014-01-08  2014-01-17      9        rapid   李汶玲   叶天英   \n",
      "..           ...         ...         ...    ...          ...   ...   ...   \n",
      "95  tournament_1  2014-01-08  2014-01-17      9        rapid   李琳华   齐慧智   \n",
      "96  tournament_1  2014-01-08  2014-01-17      9        rapid   冯燕家   何建芝   \n",
      "97  tournament_1  2014-01-08  2014-01-17      9        rapid    杨承    张燕   \n",
      "98  tournament_1  2014-01-08  2014-01-17      9        rapid   张家懿   王千迅   \n",
      "99  tournament_1  2014-01-08  2014-01-17      9        rapid   沈岚鸿   李文子   \n",
      "\n",
      "          date  result                id  \n",
      "0   2014-01-08     0.5    tournament_1_1  \n",
      "1   2014-01-08     0.5    tournament_1_2  \n",
      "2   2014-01-08     0.5    tournament_1_3  \n",
      "3   2014-01-08     1.0    tournament_1_4  \n",
      "4   2014-01-08     0.5    tournament_1_5  \n",
      "..         ...     ...               ...  \n",
      "95  2014-01-10     1.0   tournament_1_96  \n",
      "96  2014-01-10     0.0   tournament_1_97  \n",
      "97  2014-01-10     0.0   tournament_1_98  \n",
      "98  2014-01-10     0.0   tournament_1_99  \n",
      "99  2014-01-11     1.0  tournament_1_100  \n",
      "\n",
      "[100 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# Filter rows where the 'name' column equals 'tournament_1'\n",
    "filtered_df = final_df[final_df['name'] == 'tournament_1']\n",
    "\n",
    "# Display the first 100 rows of the filtered DataFrame\n",
    "print(filtered_df.head(100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "6edc139d-7fe5-4c11-a00c-f8e2ec5cee2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            name  start_date    end_date  tours time_control white black  \\\n",
      "0   tournament_1  2014-01-08  2014-01-17      9        rapid   贾叶珍   范辰妮   \n",
      "1   tournament_1  2014-01-08  2014-01-17      9        rapid   吕亚光   李嘉爵   \n",
      "2   tournament_1  2014-01-08  2014-01-17      9        rapid   刘奇喜   刘晓鹏   \n",
      "3   tournament_1  2014-01-08  2014-01-17      9        rapid   陆桂姐   郑新聪   \n",
      "4   tournament_1  2014-01-08  2014-01-17      9        rapid   李汶玲   叶天英   \n",
      "..           ...         ...         ...    ...          ...   ...   ...   \n",
      "95  tournament_1  2014-01-08  2014-01-17      9        rapid   李琳华   齐慧智   \n",
      "96  tournament_1  2014-01-08  2014-01-17      9        rapid   冯燕家   何建芝   \n",
      "97  tournament_1  2014-01-08  2014-01-17      9        rapid    杨承    张燕   \n",
      "98  tournament_1  2014-01-08  2014-01-17      9        rapid   张家懿   王千迅   \n",
      "99  tournament_1  2014-01-08  2014-01-17      9        rapid   沈岚鸿   李文子   \n",
      "\n",
      "          date  result                id  \n",
      "0   2014-01-08     0.5    tournament_1_1  \n",
      "1   2014-01-08     0.5    tournament_1_2  \n",
      "2   2014-01-08     0.5    tournament_1_3  \n",
      "3   2014-01-08     1.0    tournament_1_4  \n",
      "4   2014-01-08     0.5    tournament_1_5  \n",
      "..         ...     ...               ...  \n",
      "95  2014-01-10     1.0   tournament_1_96  \n",
      "96  2014-01-10     0.0   tournament_1_97  \n",
      "97  2014-01-10     0.0   tournament_1_98  \n",
      "98  2014-01-10     0.0   tournament_1_99  \n",
      "99  2014-01-11     1.0  tournament_1_100  \n",
      "\n",
      "[100 rows x 10 columns]\n",
      "Count of records with name 'tournament_1': 3586\n"
     ]
    }
   ],
   "source": [
    "# Filter rows where the 'name' column equals 'tournament_1'\n",
    "filtered_df = final_df[final_df['name'] == 'tournament_1']\n",
    "\n",
    "# Display the first 100 rows of the filtered DataFrame\n",
    "print(filtered_df.head(100))\n",
    "\n",
    "# Get the count of records where 'name' is 'tournament_1'\n",
    "record_count = filtered_df.shape[0]\n",
    "print(f\"Count of records with name 'tournament_1': {record_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "61293a4a-7aca-4741-813b-12373d879b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in 'white': 293\n",
      "Counts of each unique value in 'white':\n",
      "white\n",
      "Lv, Yiguo      26\n",
      "Cai, Qi        26\n",
      "Zhang, Muli    24\n",
      "Chen, Yuyu     24\n",
      "Liang, Qing    24\n",
      "               ..\n",
      "郑新聪             8\n",
      "刘星梅             8\n",
      "袁宪萍             8\n",
      "范辰妮             6\n",
      "Lv, Yinwen      6\n",
      "Name: count, Length: 293, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming final_df is already created from the previous code\n",
    "# For demonstration, here's how you would use it:\n",
    "\n",
    "# Get the number of unique values in the 'white' column\n",
    "unique_count = final_df[\"white\"].nunique()\n",
    "print(f\"Number of unique values in 'white': {unique_count}\")\n",
    "\n",
    "# Get the count of each unique value in the 'white' column\n",
    "value_counts = final_df[\"white\"].value_counts()\n",
    "print(\"Counts of each unique value in 'white':\")\n",
    "print(value_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6214bd01-fc28-47a0-9469-044399228ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['name', 'start_date', 'end_date', 'tours', 'time_control', 'white',\n",
       "       'black', 'date', 'result', 'id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "3ab01ac4-444c-4087-ad89-a9e0aea299ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Name</th>\n",
       "      <th>Data_type</th>\n",
       "      <th>Unique_values</th>\n",
       "      <th>% of null values</th>\n",
       "      <th>Total values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>name</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>start_date</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>end_date</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tours</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>time_control</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>white</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>black</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>date</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>result</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>id</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>1793</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature Name    Data_type  Unique_values  % of null values  Total values\n",
       "0          name  Categorical              1               0.0          3586\n",
       "1    start_date  Categorical              5               0.0          3586\n",
       "2      end_date  Categorical              6               0.0          3586\n",
       "3         tours  Categorical              3               0.0          3586\n",
       "4  time_control  Categorical              2               0.0          3586\n",
       "5         white  Categorical            293               0.0          3586\n",
       "6         black  Categorical            293               0.0          3586\n",
       "7          date  Categorical             38               0.0          3586\n",
       "8        result  Categorical              3               0.0          3586\n",
       "9            id  Categorical           1793               0.0          3586"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Summary\n",
    "data_summary = []\n",
    "\n",
    "Categorical_features = ['name', 'start_date', 'end_date', 'tours', 'time_control', 'white',\n",
    "       'black', 'date', 'result', 'id']\n",
    "\n",
    "for col in final_df.columns:\n",
    "    percent_null = final_df[col].isnull().mean()*100\n",
    "    total_unique = final_df[col].nunique()\n",
    "    total_values = final_df[col].count()\n",
    "    # data_type = \"Numerical\" if pd.api.types.is_numeric_dtype(train[col]) else \"Categorical\"\n",
    "    data_type = \"Numerical\" if col not in Categorical_features else \"Categorical\"\n",
    "\n",
    "    data_summary.append([col, data_type, total_unique,  percent_null, total_values])\n",
    "\n",
    "data_summary = pd.DataFrame(data_summary, columns = ['Feature Name', 'Data_type', 'Unique_values', '% of null values', 'Total values'])\n",
    "data_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2cfdedc3-57a8-4c0e-83db-80e75238b4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            name  start_date    end_date  tours time_control white black  \\\n",
      "33  tournament_1  2014-01-08  2014-01-17      9        rapid   曹灵缨   陆桂姐   \n",
      "34  tournament_1  2014-01-08  2014-01-17      9        rapid   王由航   刘家坚   \n",
      "35  tournament_1  2014-01-08  2014-01-17      9        rapid   毛心磊   张志琼   \n",
      "36  tournament_1  2014-01-08  2014-01-17      9        rapid   沈岚鸿   徐先广   \n",
      "37  tournament_1  2014-01-08  2014-01-17      9        rapid   李巧芸   刘宇福   \n",
      "38  tournament_1  2014-01-08  2014-01-17      9        rapid   范辰妮   范存妞   \n",
      "39  tournament_1  2014-01-08  2014-01-17      9        rapid   李嘉爵   李文子   \n",
      "40  tournament_1  2014-01-08  2014-01-17      9        rapid   刘晓鹏    刘先   \n",
      "41  tournament_1  2014-01-08  2014-01-17      9        rapid   叶天英   张延营   \n",
      "42  tournament_1  2014-01-08  2014-01-17      9        rapid    杨钰   张安甜   \n",
      "43  tournament_1  2014-01-08  2014-01-17      9        rapid    方东   李松江   \n",
      "44  tournament_1  2014-01-08  2014-01-17      9        rapid   余冬春    梁良   \n",
      "45  tournament_1  2014-01-08  2014-01-17      9        rapid   阎斯钧   李守超   \n",
      "46  tournament_1  2014-01-08  2014-01-17      9        rapid   张半植   王剑铭   \n",
      "47  tournament_1  2014-01-08  2014-01-17      9        rapid   董玉波   贾叶珍   \n",
      "48  tournament_1  2014-01-08  2014-01-17      9        rapid   袁宪萍   吕亚光   \n",
      "49  tournament_1  2014-01-08  2014-01-17      9        rapid   刘星梅   刘奇喜   \n",
      "50  tournament_1  2014-01-08  2014-01-17      9        rapid    魏兴   李汶玲   \n",
      "51  tournament_1  2014-01-08  2014-01-17      9        rapid    彭国    薛冠   \n",
      "52  tournament_1  2014-01-08  2014-01-17      9        rapid   郑新聪   王永赟   \n",
      "53  tournament_1  2014-01-08  2014-01-17      9        rapid   齐慧智   杨莎强   \n",
      "54  tournament_1  2014-01-08  2014-01-17      9        rapid    吴秋   孟芳全   \n",
      "55  tournament_1  2014-01-08  2014-01-17      9        rapid   吴昱明   钟弘存   \n",
      "56  tournament_1  2014-01-08  2014-01-17      9        rapid   朱有荣   袁小昆   \n",
      "57  tournament_1  2014-01-08  2014-01-17      9        rapid   何建芝   杨燕波   \n",
      "58  tournament_1  2014-01-08  2014-01-17      9        rapid   何驿艳   陈思刚   \n",
      "59  tournament_1  2014-01-08  2014-01-17      9        rapid    梁扬   董海非   \n",
      "60  tournament_1  2014-01-08  2014-01-17      9        rapid    张燕   毛均承   \n",
      "61  tournament_1  2014-01-08  2014-01-17      9        rapid   张木兴   冯燕家   \n",
      "62  tournament_1  2014-01-08  2014-01-17      9        rapid   王千迅   杨佩义   \n",
      "63  tournament_1  2014-01-08  2014-01-17      9        rapid    殷小   李琳华   \n",
      "64  tournament_1  2014-01-08  2014-01-17      9        rapid   谢庆麟    杨承   \n",
      "65  tournament_1  2014-01-08  2014-01-17      9        rapid   陈音亮   张家懿   \n",
      "66  tournament_1  2014-01-08  2014-01-17      9        rapid   刘家坚   沈岚鸿   \n",
      "67  tournament_1  2014-01-08  2014-01-17      9        rapid   范存妞   曹灵缨   \n",
      "68  tournament_1  2014-01-08  2014-01-17      9        rapid   李文子   毛心磊   \n",
      "69  tournament_1  2014-01-08  2014-01-17      9        rapid   张延营   李巧芸   \n",
      "70  tournament_1  2014-01-08  2014-01-17      9        rapid   李守超    杨钰   \n",
      "71  tournament_1  2014-01-08  2014-01-17      9        rapid   陆桂姐    方东   \n",
      "72  tournament_1  2014-01-08  2014-01-17      9        rapid   张志琼   张半植   \n",
      "73  tournament_1  2014-01-08  2014-01-17      9        rapid   刘宇福   董玉波   \n",
      "74  tournament_1  2014-01-08  2014-01-17      9        rapid    刘先   刘星梅   \n",
      "75  tournament_1  2014-01-08  2014-01-17      9        rapid    梁良    彭国   \n",
      "76  tournament_1  2014-01-08  2014-01-17      9        rapid   杨莎强   王由航   \n",
      "77  tournament_1  2014-01-08  2014-01-17      9        rapid   杨燕波   刘晓鹏   \n",
      "78  tournament_1  2014-01-08  2014-01-17      9        rapid   毛均承   余冬春   \n",
      "79  tournament_1  2014-01-08  2014-01-17      9        rapid   徐先广   袁宪萍   \n",
      "80  tournament_1  2014-01-08  2014-01-17      9        rapid   张安甜    魏兴   \n",
      "81  tournament_1  2014-01-08  2014-01-17      9        rapid   李松江    吴秋   \n",
      "82  tournament_1  2014-01-08  2014-01-17      9        rapid   王剑铭    梁扬   \n",
      "\n",
      "          date  result               id  \n",
      "33  2014-01-09     0.5  tournament_1_34  \n",
      "34  2014-01-09     0.0  tournament_1_35  \n",
      "35  2014-01-09     0.5  tournament_1_36  \n",
      "36  2014-01-09     1.0  tournament_1_37  \n",
      "37  2014-01-09     0.5  tournament_1_38  \n",
      "38  2014-01-09     0.0  tournament_1_39  \n",
      "39  2014-01-09     0.0  tournament_1_40  \n",
      "40  2014-01-09     0.5  tournament_1_41  \n",
      "41  2014-01-09     0.0  tournament_1_42  \n",
      "42  2014-01-09     1.0  tournament_1_43  \n",
      "43  2014-01-09     1.0  tournament_1_44  \n",
      "44  2014-01-09     0.5  tournament_1_45  \n",
      "45  2014-01-09     0.0  tournament_1_46  \n",
      "46  2014-01-09     1.0  tournament_1_47  \n",
      "47  2014-01-09     1.0  tournament_1_48  \n",
      "48  2014-01-09     0.5  tournament_1_49  \n",
      "49  2014-01-09     1.0  tournament_1_50  \n",
      "50  2014-01-09     0.5  tournament_1_51  \n",
      "51  2014-01-09     1.0  tournament_1_52  \n",
      "52  2014-01-09     0.5  tournament_1_53  \n",
      "53  2014-01-09     0.0  tournament_1_54  \n",
      "54  2014-01-09     1.0  tournament_1_55  \n",
      "55  2014-01-09     0.5  tournament_1_56  \n",
      "56  2014-01-09     0.5  tournament_1_57  \n",
      "57  2014-01-09     0.0  tournament_1_58  \n",
      "58  2014-01-09     0.5  tournament_1_59  \n",
      "59  2014-01-09     1.0  tournament_1_60  \n",
      "60  2014-01-09     0.0  tournament_1_61  \n",
      "61  2014-01-09     1.0  tournament_1_62  \n",
      "62  2014-01-09     0.0  tournament_1_63  \n",
      "63  2014-01-09     0.5  tournament_1_64  \n",
      "64  2014-01-09     1.0  tournament_1_65  \n",
      "65  2014-01-09     1.0  tournament_1_66  \n",
      "66  2014-01-10     0.0  tournament_1_67  \n",
      "67  2014-01-10     0.5  tournament_1_68  \n",
      "68  2014-01-10     1.0  tournament_1_69  \n",
      "69  2014-01-10     1.0  tournament_1_70  \n",
      "70  2014-01-10     0.5  tournament_1_71  \n",
      "71  2014-01-10     1.0  tournament_1_72  \n",
      "72  2014-01-10     1.0  tournament_1_73  \n",
      "73  2014-01-10     1.0  tournament_1_74  \n",
      "74  2014-01-10     0.0  tournament_1_75  \n",
      "75  2014-01-10     1.0  tournament_1_76  \n",
      "76  2014-01-10     0.5  tournament_1_77  \n",
      "77  2014-01-10     0.0  tournament_1_78  \n",
      "78  2014-01-10     1.0  tournament_1_79  \n",
      "79  2014-01-10     1.0  tournament_1_80  \n",
      "80  2014-01-10     1.0  tournament_1_81  \n",
      "81  2014-01-10     0.0  tournament_1_82  \n",
      "82  2014-01-10     1.0  tournament_1_83  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming final_df already exists and has the columns 'name', 'start_date', and 'date'\n",
    "\n",
    "# Filter rows where the 'name' column equals 'tournament_1' and 'start_date' is not equal to 'date'\n",
    "filtered_df = final_df[(final_df['name'] == 'tournament_1') & (final_df['start_date'] != final_df['date'])]\n",
    "\n",
    "# Display the first 50 rows of the filtered DataFrame\n",
    "print(filtered_df.head(50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "e089ae38-d6fe-47e2-a0e2-b37f91f649d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             mean  count\n",
      "name         date                       \n",
      "tournament_1 2014-01-08  0.636364     66\n",
      "             2014-01-09  0.545455     66\n",
      "             2014-01-10  0.621212     66\n",
      "             2014-01-11  0.621212     66\n",
      "             2014-01-12  0.545455     66\n",
      "             2014-01-13  0.500000     66\n",
      "             2014-01-14  0.651515     66\n",
      "             2014-01-15  0.500000    116\n",
      "             2014-01-16  0.651515     66\n",
      "             2014-01-17  0.580000     50\n",
      "             2014-01-19  0.420000     50\n",
      "             2014-01-21  0.520000     50\n",
      "             2014-01-23  0.440000     50\n",
      "             2014-01-25  0.620000     50\n",
      "             2014-01-27  0.520000     50\n",
      "             2014-01-29  0.560000     50\n",
      "             2014-01-31  0.600000     50\n",
      "             2014-02-02  0.600000     50\n",
      "             2014-02-04  0.420000     50\n",
      "             2014-02-06  0.600000     50\n",
      "             2014-08-29  0.611111     72\n",
      "             2014-08-31  0.416667     72\n",
      "             2014-09-02  0.694444     72\n",
      "             2014-09-04  0.525943    424\n",
      "             2014-09-05  0.583333     48\n",
      "             2014-09-06  0.625000    120\n",
      "             2014-09-07  0.562500     48\n",
      "             2014-09-08  0.522135    768\n",
      "             2014-09-09  0.583333     48\n",
      "             2014-09-10  0.675000    120\n",
      "             2014-09-11  0.604167     48\n",
      "             2014-09-12  0.491667    120\n",
      "             2014-09-13  0.604167     48\n",
      "             2014-09-14  0.525000    120\n",
      "             2014-09-15  0.500000     48\n",
      "             2014-09-16  0.486111     72\n",
      "             2014-09-18  0.638889     72\n",
      "             2014-09-20  0.430556     72\n"
     ]
    }
   ],
   "source": [
    "# print(train.groupby(\"Gender\").mean()[\"Purchase\"])\n",
    "#print(final_df.groupby(by = [\"name\",\"date\"])[\"result\"].mean(),[\"result\"].count())\n",
    "#pd.pivot_table(final_df, index = 'date', columns='name', values  = 'result', aggfunc={'result':np.mean,'result':np.count})\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Group by 'name' and 'date', then calculate the mean and count of 'result'\n",
    "grouped = final_df.groupby(by=['name', 'date'])['result'].agg(['mean', 'count'])\n",
    "print(grouped)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d7cfc327-3d30-4448-9f4b-3ca2e73ffeb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame has been saved to F:\\jupyter\\final_df2.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming final_df is already created and contains data\n",
    "\n",
    "# Define the file path where you want to save the CSV file\n",
    "file_path = r'F:\\jupyter\\final_df2.csv'\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "final_df.to_csv(file_path, index=False)\n",
    "\n",
    "print(f\"DataFrame has been saved to {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cb45f3be-a86c-4efd-b7ca-b5d2ecfd0e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        True\n",
       "1        True\n",
       "2        True\n",
       "3        True\n",
       "4        True\n",
       "        ...  \n",
       "3581    False\n",
       "3582    False\n",
       "3583    False\n",
       "3584    False\n",
       "3585    False\n",
       "Name: name, Length: 3586, dtype: bool"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df[\"name\"]=='tournament_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "545ea207-814b-425b-b7c7-b14de432b254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>tours</th>\n",
       "      <th>time_control</th>\n",
       "      <th>white</th>\n",
       "      <th>black</th>\n",
       "      <th>date</th>\n",
       "      <th>result</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tournament_1</td>\n",
       "      <td>2014-01-08</td>\n",
       "      <td>2014-01-17</td>\n",
       "      <td>9</td>\n",
       "      <td>rapid</td>\n",
       "      <td>贾叶珍</td>\n",
       "      <td>范辰妮</td>\n",
       "      <td>2014-01-08</td>\n",
       "      <td>0.5</td>\n",
       "      <td>tournament_1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tournament_1</td>\n",
       "      <td>2014-01-08</td>\n",
       "      <td>2014-01-17</td>\n",
       "      <td>9</td>\n",
       "      <td>rapid</td>\n",
       "      <td>吕亚光</td>\n",
       "      <td>李嘉爵</td>\n",
       "      <td>2014-01-08</td>\n",
       "      <td>0.5</td>\n",
       "      <td>tournament_1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tournament_1</td>\n",
       "      <td>2014-01-08</td>\n",
       "      <td>2014-01-17</td>\n",
       "      <td>9</td>\n",
       "      <td>rapid</td>\n",
       "      <td>刘奇喜</td>\n",
       "      <td>刘晓鹏</td>\n",
       "      <td>2014-01-08</td>\n",
       "      <td>0.5</td>\n",
       "      <td>tournament_1_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tournament_1</td>\n",
       "      <td>2014-01-08</td>\n",
       "      <td>2014-01-17</td>\n",
       "      <td>9</td>\n",
       "      <td>rapid</td>\n",
       "      <td>陆桂姐</td>\n",
       "      <td>郑新聪</td>\n",
       "      <td>2014-01-08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>tournament_1_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tournament_1</td>\n",
       "      <td>2014-01-08</td>\n",
       "      <td>2014-01-17</td>\n",
       "      <td>9</td>\n",
       "      <td>rapid</td>\n",
       "      <td>李汶玲</td>\n",
       "      <td>叶天英</td>\n",
       "      <td>2014-01-08</td>\n",
       "      <td>0.5</td>\n",
       "      <td>tournament_1_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>tournament_100</td>\n",
       "      <td>2014-08-29</td>\n",
       "      <td>2014-09-22</td>\n",
       "      <td>12</td>\n",
       "      <td>classic</td>\n",
       "      <td>陈一</td>\n",
       "      <td>金心峰</td>\n",
       "      <td>2014-09-18</td>\n",
       "      <td>0.5</td>\n",
       "      <td>tournament_100_370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>tournament_100</td>\n",
       "      <td>2014-08-29</td>\n",
       "      <td>2014-09-22</td>\n",
       "      <td>12</td>\n",
       "      <td>classic</td>\n",
       "      <td>郭周哲</td>\n",
       "      <td>彭国</td>\n",
       "      <td>2014-09-18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>tournament_100_371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>tournament_100</td>\n",
       "      <td>2014-08-29</td>\n",
       "      <td>2014-09-22</td>\n",
       "      <td>12</td>\n",
       "      <td>classic</td>\n",
       "      <td>吴雄苍</td>\n",
       "      <td>魏兴</td>\n",
       "      <td>2014-09-18</td>\n",
       "      <td>0.5</td>\n",
       "      <td>tournament_100_372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>tournament_100</td>\n",
       "      <td>2014-08-29</td>\n",
       "      <td>2014-09-22</td>\n",
       "      <td>12</td>\n",
       "      <td>classic</td>\n",
       "      <td>郝华琳</td>\n",
       "      <td>丁晨彤</td>\n",
       "      <td>2014-09-18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>tournament_100_373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>tournament_100</td>\n",
       "      <td>2014-08-29</td>\n",
       "      <td>2014-09-22</td>\n",
       "      <td>12</td>\n",
       "      <td>classic</td>\n",
       "      <td>冯柏贞</td>\n",
       "      <td>何驿艳</td>\n",
       "      <td>2014-09-18</td>\n",
       "      <td>0.5</td>\n",
       "      <td>tournament_100_374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                name  start_date    end_date  tours time_control white black  \\\n",
       "0       tournament_1  2014-01-08  2014-01-17      9        rapid   贾叶珍   范辰妮   \n",
       "1       tournament_1  2014-01-08  2014-01-17      9        rapid   吕亚光   李嘉爵   \n",
       "2       tournament_1  2014-01-08  2014-01-17      9        rapid   刘奇喜   刘晓鹏   \n",
       "3       tournament_1  2014-01-08  2014-01-17      9        rapid   陆桂姐   郑新聪   \n",
       "4       tournament_1  2014-01-08  2014-01-17      9        rapid   李汶玲   叶天英   \n",
       "...              ...         ...         ...    ...          ...   ...   ...   \n",
       "1995  tournament_100  2014-08-29  2014-09-22     12      classic    陈一   金心峰   \n",
       "1996  tournament_100  2014-08-29  2014-09-22     12      classic   郭周哲    彭国   \n",
       "1997  tournament_100  2014-08-29  2014-09-22     12      classic   吴雄苍    魏兴   \n",
       "1998  tournament_100  2014-08-29  2014-09-22     12      classic   郝华琳   丁晨彤   \n",
       "1999  tournament_100  2014-08-29  2014-09-22     12      classic   冯柏贞   何驿艳   \n",
       "\n",
       "            date  result                  id  \n",
       "0     2014-01-08     0.5      tournament_1_1  \n",
       "1     2014-01-08     0.5      tournament_1_2  \n",
       "2     2014-01-08     0.5      tournament_1_3  \n",
       "3     2014-01-08     1.0      tournament_1_4  \n",
       "4     2014-01-08     0.5      tournament_1_5  \n",
       "...          ...     ...                 ...  \n",
       "1995  2014-09-18     0.5  tournament_100_370  \n",
       "1996  2014-09-18     1.0  tournament_100_371  \n",
       "1997  2014-09-18     0.5  tournament_100_372  \n",
       "1998  2014-09-18     1.0  tournament_100_373  \n",
       "1999  2014-09-18     0.5  tournament_100_374  \n",
       "\n",
       "[2000 rows x 10 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "938f7812-708c-479c-84d2-80e5a7bba292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>name</th>\n",
       "      <th>white</th>\n",
       "      <th>tours</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>tournament_1</td>\n",
       "      <td>何建芝</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>tournament_1</td>\n",
       "      <td>何驿艳</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>tournament_1</td>\n",
       "      <td>冯燕家</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>tournament_1</td>\n",
       "      <td>刘先</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>tournament_1</td>\n",
       "      <td>刘奇喜</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.0</td>\n",
       "      <td>tournament_100</td>\n",
       "      <td>李秀寿</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0</td>\n",
       "      <td>tournament_100</td>\n",
       "      <td>杨慧</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.0</td>\n",
       "      <td>tournament_100</td>\n",
       "      <td>杨承</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.0</td>\n",
       "      <td>tournament_100</td>\n",
       "      <td>林源浩</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.0</td>\n",
       "      <td>tournament_100</td>\n",
       "      <td>梁良</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    result            name white  tours  count\n",
       "0      0.0    tournament_1   何建芝      9      4\n",
       "1      0.0    tournament_1   何驿艳      9      2\n",
       "2      0.0    tournament_1   冯燕家      9      6\n",
       "3      0.0    tournament_1    刘先      9      2\n",
       "4      0.0    tournament_1   刘奇喜      9      2\n",
       "..     ...             ...   ...    ...    ...\n",
       "95     0.0  tournament_100   李秀寿     12      2\n",
       "96     0.0  tournament_100    杨慧     12      4\n",
       "97     0.0  tournament_100    杨承     12      4\n",
       "98     0.0  tournament_100   林源浩     12      4\n",
       "99     0.0  tournament_100    梁良     12      2\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you have a DataFrame named 'final_df'\n",
    "\n",
    "# Filter the DataFrame where 'name' is 'tournament_1' and 'white' is 'Huang, Mengli'\n",
    "#filtered_df = final_df[(final_df['name'] == 'tournament_10') & (final_df['white'] == 'Jiang, Degang')]\n",
    "\n",
    "# Group by 'result', 'name', and 'white', then count occurrences of each group\n",
    "grouped_df = final_df.groupby(['result', 'name', 'white','tours']).size().reset_index(name='count')\n",
    "\n",
    "# Display the result\n",
    "\n",
    "grouped_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6e88d2f-7e52-40d4-b047-a531393ab3f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>name</th>\n",
       "      <th>white</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>tournament_10</td>\n",
       "      <td>Jiang, Degang</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>tournament_10</td>\n",
       "      <td>Jiang, Degang</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   result           name          white  count\n",
       "0     0.5  tournament_10  Jiang, Degang     10\n",
       "1     1.0  tournament_10  Jiang, Degang      2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you have a DataFrame named 'final_df'\n",
    "\n",
    "# Filter the DataFrame where 'name' is 'tournament_1' and 'white' is 'Huang, Mengli'\n",
    "#filtered_df = final_df[(final_df['name'] == 'tournament_10') & (final_df['white'] == 'Jiang, Degang')]\n",
    "\n",
    "# Group by 'result', 'name', and 'white', then count occurrences of each group\n",
    "grouped_df = filtered_df.groupby(['result', 'name', 'white']).size().reset_index(name='count')\n",
    "\n",
    "# Display the result\n",
    "\n",
    "grouped_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5ede92e-9b7d-4444-b87b-53a497d148e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final ELO rating for Huang, Mengli: 1256.8010362280102\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you have a DataFrame named 'final_df'\n",
    "# Example of initializing ELO ratings for players\n",
    "initial_elo = 1200  # Initial ELO score for each player\n",
    "\n",
    "# Create a dictionary to store the ELO ratings of players\n",
    "elo_ratings = {'Huang, Mengli': initial_elo, 'Jiang, Degang': initial_elo}\n",
    "\n",
    "# Function to calculate the expected score\n",
    "def expected_score(elo_a, elo_b):\n",
    "    return 1 / (1 + 10**((elo_b - elo_a) / 400))\n",
    "\n",
    "# Function to update the ELO rating\n",
    "def update_elo(elo, expected, actual, k=32):\n",
    "    return elo + k * (actual - expected)\n",
    "\n",
    "# Iterate over each match and update the ELO score for 'Huang, Mengli'\n",
    "for _, row in final_df.iterrows():\n",
    "    if row['white'] == 'Huang, Mengli':\n",
    "        opponent = row['black']  # Assuming the opponent's name is in the 'black' column\n",
    "    else:\n",
    "        opponent = row['white']\n",
    "    \n",
    "    result = row['result']\n",
    "    \n",
    "    # Get current ELO ratings\n",
    "    elo_a = elo_ratings['Huang, Mengli']\n",
    "    elo_b = elo_ratings.get(opponent, initial_elo)\n",
    "    \n",
    "    # Calculate expected score\n",
    "    expected_a = expected_score(elo_a, elo_b)\n",
    "    \n",
    "    # Update ELO based on match result\n",
    "    actual_score = result  # Assuming 1.0 for win, 0.5 for draw, 0.0 for loss\n",
    "    new_elo_a = update_elo(elo_a, expected_a, actual_score)\n",
    "    \n",
    "    # Update the dictionary with new ELO score\n",
    "    elo_ratings['Huang, Mengli'] = new_elo_a\n",
    "    elo_ratings[opponent] = update_elo(elo_b, 1 - expected_a, 1 - actual_score)\n",
    "\n",
    "# Output the final ELO rating for Huang, Mengli\n",
    "print(f\"Final ELO rating for Huang, Mengli: {elo_ratings['Huang, Mengli']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "453e65d4-b8bf-45cd-ac75-08e40bd4cb1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Player          ELO\n",
      "0    Wang, Jianyao  1463.505303\n",
      "1    Jiang, Degang  1421.993895\n",
      "2       Li, Xingbo  1407.849396\n",
      "3      Zhu, Erzhou  1405.206143\n",
      "4              孙义敏  1396.713026\n",
      "..             ...          ...\n",
      "288  Zhang, Yajuan  1036.347932\n",
      "289     Lu, Yingfu  1028.660479\n",
      "290    Zhang, Muli  1005.389369\n",
      "291            李禄娟  1001.667972\n",
      "292             段振   967.929374\n",
      "\n",
      "[293 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example initial ELO score\n",
    "initial_elo = 1200\n",
    "\n",
    "# Create a dictionary to store ELO ratings of players\n",
    "elo_ratings = {}\n",
    "\n",
    "# Function to calculate the expected score\n",
    "def expected_score(elo_a, elo_b):\n",
    "    return 1 / (1 + 10**((elo_b - elo_a) / 400))\n",
    "\n",
    "# Function to update the ELO rating\n",
    "def update_elo(elo, expected, actual, k=32):\n",
    "    return elo + k * (actual - expected)\n",
    "\n",
    "# Iterate over each match in the DataFrame and update ELO scores\n",
    "for _, row in final_df.iterrows():\n",
    "    white_player = row['white']\n",
    "    black_player = row['black']\n",
    "    result = row['result']\n",
    "    \n",
    "    # Initialize ELO scores if players are not in the dictionary\n",
    "    if white_player not in elo_ratings:\n",
    "        elo_ratings[white_player] = initial_elo\n",
    "    if black_player not in elo_ratings:\n",
    "        elo_ratings[black_player] = initial_elo\n",
    "    \n",
    "    # Get current ELO ratings\n",
    "    elo_white = elo_ratings[white_player]\n",
    "    elo_black = elo_ratings[black_player]\n",
    "    \n",
    "    # Calculate expected scores\n",
    "    expected_white = expected_score(elo_white, elo_black)\n",
    "    expected_black = 1 - expected_white\n",
    "    \n",
    "    # Determine actual scores based on match result\n",
    "    if result == 1.0:  # White wins\n",
    "        actual_white = 1.0\n",
    "        actual_black = 0.0\n",
    "    elif result == 0.0:  # Black wins\n",
    "        actual_white = 0.0\n",
    "        actual_black = 1.0\n",
    "    else:  # Draw\n",
    "        actual_white = 0.5\n",
    "        actual_black = 0.5\n",
    "    \n",
    "    # Update ELO ratings\n",
    "    elo_ratings[white_player] = update_elo(elo_white, expected_white, actual_white)\n",
    "    elo_ratings[black_player] = update_elo(elo_black, expected_black, actual_black)\n",
    "\n",
    "# Convert ELO ratings to a DataFrame for easier viewing\n",
    "elo_df = pd.DataFrame(list(elo_ratings.items()), columns=['Player', 'ELO'])\n",
    "elo_df = elo_df.sort_values(by='ELO', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Display the final ELO ratings\n",
    "print(elo_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b9e93947-9af7-472d-8b56-175d1422f2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           name  start_date    end_date  tours time_control white black  \\\n",
      "0  tournament_1  2014-01-08  2014-01-17      9        rapid   贾叶珍   范辰妮   \n",
      "1  tournament_1  2014-01-08  2014-01-17      9        rapid   吕亚光   李嘉爵   \n",
      "2  tournament_1  2014-01-08  2014-01-17      9        rapid   刘奇喜   刘晓鹏   \n",
      "3  tournament_1  2014-01-08  2014-01-17      9        rapid   陆桂姐   郑新聪   \n",
      "4  tournament_1  2014-01-08  2014-01-17      9        rapid   李汶玲   叶天英   \n",
      "\n",
      "         date  result              id    White_ELO    Black_ELO    White_ELO  \\\n",
      "0  2014-01-08     0.5  tournament_1_1  1236.587775  1110.330075  1236.587775   \n",
      "1  2014-01-08     0.5  tournament_1_2  1271.590010  1187.634486  1271.590010   \n",
      "2  2014-01-08     0.5  tournament_1_3  1142.352471  1266.736660  1142.352471   \n",
      "3  2014-01-08     1.0  tournament_1_4  1247.252651  1116.404022  1247.252651   \n",
      "4  2014-01-08     0.5  tournament_1_5  1086.099543  1179.171668  1086.099543   \n",
      "\n",
      "     Black_ELO  \n",
      "0  1110.330075  \n",
      "1  1187.634486  \n",
      "2  1266.736660  \n",
      "3  1116.404022  \n",
      "4  1179.171668  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "final_df_duplicates=final_df\n",
    "# Example initial ELO score\n",
    "initial_elo = 1200\n",
    "\n",
    "# Create a dictionary to store ELO ratings of players\n",
    "elo_ratings = {}\n",
    "\n",
    "# Function to calculate the expected score\n",
    "def expected_score(elo_a, elo_b):\n",
    "    return 1 / (1 + 10**((elo_b - elo_a) / 400))\n",
    "\n",
    "# Function to update the ELO rating\n",
    "def update_elo(elo, expected, actual, k=32):\n",
    "    return elo + k * (actual - expected)\n",
    "\n",
    "# Iterate over each match in the DataFrame and update ELO scores\n",
    "for _, row in final_df_duplicates.iterrows():\n",
    "    white_player = row['white']\n",
    "    black_player = row['black']\n",
    "    result = row['result']\n",
    "    \n",
    "    # Initialize ELO scores if players are not in the dictionary\n",
    "    if white_player not in elo_ratings:\n",
    "        elo_ratings[white_player] = initial_elo\n",
    "    if black_player not in elo_ratings:\n",
    "        elo_ratings[black_player] = initial_elo\n",
    "    \n",
    "    # Get current ELO ratings\n",
    "    elo_white = elo_ratings[white_player]\n",
    "    elo_black = elo_ratings[black_player]\n",
    "    \n",
    "    # Calculate expected scores\n",
    "    expected_white = expected_score(elo_white, elo_black)\n",
    "    expected_black = 1 - expected_white\n",
    "    \n",
    "    # Determine actual scores based on match result\n",
    "    if result == 1.0:  # White wins\n",
    "        actual_white = 1.0\n",
    "        actual_black = 0.0\n",
    "    elif result == 0.0:  # Black wins\n",
    "        actual_white = 0.0\n",
    "        actual_black = 1.0\n",
    "    else:  # Draw\n",
    "        actual_white = 0.5\n",
    "        actual_black = 0.5\n",
    "    \n",
    "    # Update ELO ratings\n",
    "    elo_ratings[white_player] = update_elo(elo_white, expected_white, actual_white)\n",
    "    elo_ratings[black_player] = update_elo(elo_black, expected_black, actual_black)\n",
    "\n",
    "# Convert ELO ratings to a DataFrame\n",
    "elo_df = pd.DataFrame(list(elo_ratings.items()), columns=['Player', 'ELO'])\n",
    "\n",
    "# Merge the ELO ratings back into the original DataFrame\n",
    "final_df_duplicates = final_df_duplicates.merge(elo_df, left_on='white', right_on='Player', how='left')\n",
    "final_df_duplicates = final_df_duplicates.rename(columns={'ELO': 'White_ELO'}).drop(columns=['Player'])\n",
    "\n",
    "final_df_duplicates = final_df_duplicates.merge(elo_df, left_on='black', right_on='Player', how='left')\n",
    "final_df_duplicates = final_df_duplicates.rename(columns={'ELO': 'Black_ELO'}).drop(columns=['Player'])\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(final_df_duplicates.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "eadf1df1-68eb-4222-9b5b-3af2d2b985e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame has been saved to F:\\jupyter\\final_duplicates.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming final_df is already created and contains data\n",
    "\n",
    "# Define the file path where you want to save the CSV file\n",
    "file_path = r'F:\\jupyter\\final_duplicates.csv'\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "final_df_duplicates.to_csv(file_path, index=False)\n",
    "\n",
    "print(f\"DataFrame has been saved to {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ecf07b22-10f2-48c8-8671-796a1b47ccf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           name  start_date    end_date  tours time_control white black  \\\n",
      "0  tournament_1  2014-01-08  2014-01-17      9        rapid   贾叶珍   范辰妮   \n",
      "1  tournament_1  2014-01-08  2014-01-17      9        rapid   吕亚光   李嘉爵   \n",
      "2  tournament_1  2014-01-08  2014-01-17      9        rapid   刘奇喜   刘晓鹏   \n",
      "3  tournament_1  2014-01-08  2014-01-17      9        rapid   陆桂姐   郑新聪   \n",
      "4  tournament_1  2014-01-08  2014-01-17      9        rapid   李汶玲   叶天英   \n",
      "\n",
      "         date  result              id    White_ELO    Black_ELO  \n",
      "0  2014-01-08     0.5  tournament_1_1  1236.587775  1110.330075  \n",
      "1  2014-01-08     0.5  tournament_1_2  1271.590010  1187.634486  \n",
      "2  2014-01-08     0.5  tournament_1_3  1142.352471  1266.736660  \n",
      "3  2014-01-08     1.0  tournament_1_4  1247.252651  1116.404022  \n",
      "4  2014-01-08     0.5  tournament_1_5  1086.099543  1179.171668  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example initial ELO score\n",
    "initial_elo = 1200\n",
    "\n",
    "# Create a dictionary to store ELO ratings of players, key is (name, player)\n",
    "elo_ratings = {}\n",
    "\n",
    "# Function to calculate the expected score\n",
    "def expected_score(elo_a, elo_b):\n",
    "    return 1 / (1 + 10**((elo_b - elo_a) / 400))\n",
    "\n",
    "# Function to update the ELO rating\n",
    "def update_elo(elo, expected, actual, k=32):\n",
    "    return elo + k * (actual - expected)\n",
    "\n",
    "# Iterate over each match in the DataFrame and update ELO scores\n",
    "for _, row in final_df.iterrows():\n",
    "    name = row['name']\n",
    "    white_player = row['white']\n",
    "    black_player = row['black']\n",
    "    result = row['result']\n",
    "    \n",
    "    # Initialize ELO scores if players are not in the dictionary\n",
    "    if (name, white_player) not in elo_ratings:\n",
    "        elo_ratings[(name, white_player)] = initial_elo\n",
    "    if (name, black_player) not in elo_ratings:\n",
    "        elo_ratings[(name, black_player)] = initial_elo\n",
    "    \n",
    "    # Get current ELO ratings\n",
    "    elo_white = elo_ratings[(name, white_player)]\n",
    "    elo_black = elo_ratings[(name, black_player)]\n",
    "    \n",
    "    # Calculate expected scores\n",
    "    expected_white = expected_score(elo_white, elo_black)\n",
    "    expected_black = 1 - expected_white\n",
    "    \n",
    "    # Determine actual scores based on match result\n",
    "    if result == 1.0:  # White wins\n",
    "        actual_white = 1.0\n",
    "        actual_black = 0.0\n",
    "    elif result == 0.0:  # Black wins\n",
    "        actual_white = 0.0\n",
    "        actual_black = 1.0\n",
    "    else:  # Draw\n",
    "        actual_white = 0.5\n",
    "        actual_black = 0.5\n",
    "    \n",
    "    # Update ELO ratings\n",
    "    elo_ratings[(name, white_player)] = update_elo(elo_white, expected_white, actual_white)\n",
    "    elo_ratings[(name, black_player)] = update_elo(elo_black, expected_black, actual_black)\n",
    "\n",
    "# Convert ELO ratings to a DataFrame\n",
    "elo_df = pd.DataFrame([{'name': k[0], 'Player': k[1], 'ELO': v} for k, v in elo_ratings.items()])\n",
    "\n",
    "# Merge the ELO ratings back into the original DataFrame\n",
    "final_df = final_df.merge(elo_df, left_on=['name', 'white'], right_on=['name', 'Player'], how='left')\n",
    "final_df = final_df.rename(columns={'ELO': 'White_ELO'}).drop(columns=['Player'])\n",
    "\n",
    "final_df = final_df.merge(elo_df, left_on=['name', 'black'], right_on=['name', 'Player'], how='left')\n",
    "final_df = final_df.rename(columns={'ELO': 'Black_ELO'}).drop(columns=['Player'])\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(final_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6a44b927-bcbf-45b5-977f-2486aab92f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame has been saved to F:\\jupyter\\final_df3.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming final_df is already created and contains data\n",
    "\n",
    "# Define the file path where you want to save the CSV file\n",
    "file_path = r'F:\\jupyter\\final_df3.csv'\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "final_df.to_csv(file_path, index=False)\n",
    "\n",
    "print(f\"DataFrame has been saved to {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bc1093-e8ce-42d5-bb5e-baeadb9deff9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
